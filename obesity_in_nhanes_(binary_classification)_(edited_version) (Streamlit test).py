# -*- coding: utf-8 -*-
"""Obesity in NHANES (Binary classification) (Edited Version).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tCPmtkSThKolc0uOnM3nl3WyS_6I0TMO

# Initiation
"""

from google.colab import drive
drive.mount('/content/drive')

from IPython import display
display.Javascript("google.colab.output.setIframeHeight('100px');")

# @title Installing some necessary packages

# !pip install scikit-learn
# !pip install --upgrade scikit-learn
# !pip install boruta
!pip install prince
!pip install prince --upgrade
!pip install streamlit

# @title Importing the packages

import pandas as pd
import numpy as np
import streamlit as st

# @title requirements.txt

# Open and read the file
with open('/content/drive/MyDrive/requirements.txt', 'r') as file:
    content = file.read()

# Print the content of the file
print(content)

# @title Loading the main dataset

# %%capture

import pandas as pd
import numpy as np
crude_dataset = pd.read_excel('/content/drive/MyDrive/2017-prepand NHANES datasets/Relevant Dataset_New_1.xlsx')
crude_dataset.set_index('SEQN', inplace=True)
crude_dataset

# crude_dataset.columns.to_list()

# Commented out IPython magic to ensure Python compatibility.
# #%% Deleting the rows with no information regarding the outcome (i.e. BMI)
# 
# %%capture
# 
# crude_dataset = crude_dataset.dropna(subset=['BMXBMI'])
# crude_dataset

# print(crude_dataset['WHQ030M'].describe())
# print(crude_dataset['WHQ030M'].isna().sum())

"""# List of unnecessary objects(need to be dropped after the preprocessing is complete):

RIDEXPRG (Pregnancy satus)**
BMDSTATS (Body Measures Component Status Code)
BMXWT (Weight (kg))
BMIWT (Weight Comment)**
BMXHT (Standing Height (cm))
BMIHT (Standing Height Comment)**
BMDBMIC (BMI Category - Children/Youth)
BPXOSY1 (Systolic - 1st oscillometric reading)
BPXODI1 (Diastolic - 1st oscillometric reading)
BPXOSY2 (Systolic - 2nd oscillometric reading)
BPXODI2 (Diastolic - 2nd oscillometric reading)
BPXOSY3 (Systolic - 3rd oscillometric reading)
BPXODI3 (Diastolic - 3rd oscillometric reading)
DPQs (DPQ010 - 100)**
DR1DRSTZ (Dietary recall status(day1))**
DR2DRSTZ (Dietary recall status(day2))**
**!!! DO NOT FORGET to also remove the related dietary data of day 1 if only the dietary data of the first day is used!!!**

ECD010 (Mother's age when born)
ECD070B (Weight at birth, ounces)
ECQ080 (Weight more/less than 5.5 lbs)
ECQ090 (Weight more/less than 9.0 lbs)

MCQ160B (Ever told had congestive heart failure)**
MCQ170M (Do you still have thyroid problem) **bold text** Studies seem inconsisitent in showing having a thyroid problem is associated with disturbed anthropometric measurements. Moreover, the 'problems' are not specified.
MCQ170L (Do you still have a liver condition)
MCQ371A (Are you now controlling or losing weight)
MCQ371B (Are you now increasing exercise)
MCQ371C (Are you now reducing salt in diet)
MCQ371D (Are you now reducing fat in diet)

[PAQ610 (Number of days vigorous work)
PAD615 (Minutes vigorous-intensity work)
PAQ625 (Number of days moderate work)
PAD630 (Minutes moderate-intensity work)
PAQ640 (Number of days walk or bicycle)
PAD645 (Minutes walk/bicycle for transportation)
PAQ655 (Days vigorous recreational activities)
PAD660 (Minutes vigorous recreational activities)
PAQ670 (Days moderate recreational activities)
PAD675 (Minutes moderate recreational activities)]
**These physical activity attributes should be removed before data imputation. They contain a very high level of missing values.**

SLQ300 (Usual sleep time on weekdays or workdays)
SLQ310 (Usual wake time on weekdays or workdays)
SLQ320 (Usual sleep time on weekends)
SLQ330 (Usual wake time on weekends)

WHQ060 (Weight change intentional)
WHD080A - L (the methods of trying to lose weight) (21 variables)
WHQ030M (How do you consider your weight) **No valid data!! All missing!**
WHQ500 (Trying to do about weight) **No valid data!! All missing!**
WHQ520 (How often tried to lose weight) **No valid data!! All missing!**


Do not provide relevant information:
WHD010 (Current self-reported height (inches))
WHD020 (Current self-reported weight (pounds))
WHQ030 (How do you consider your weight)
WHQ040 (Like to weigh more, less or same)
WHQ060 (Weight change intentional)
WHQ070 (Tried to lose weight in past year)
WHQ225 (Times lost 10 lbs or more to lose weight)



SDMVPSU (Masked variance pseudo-PSU)
SDMVSTRA (Masked variance pseudo-stratum)
WTDRD1PP (Dietary day one sample weight)
WTDR2DPP (Dietary two-day sample weight)
DRABF (Breast-fed infant (either day))
DRDINT (Number of days of intake)**
DR1TNUMF (Number of foods/beverages reported)
DR2TNUMF (Number of foods/beverages reported)

All dietary data used to calculate HEI-2020 minus energy, macronutrients, alcohol, cholestrol, and final components of HEI-2020

All variables with equal to and more than 50% missing values





Future outcomes:
BMXWAIST (Waist Circumference (cm))
BMIWAIST (Waist Circumference Comment)
**# Be SUPER careful to exclude cases from which data could not be obtained (when regarded as outcome)**
BMXHIP (Hip Circumference (cm))
BMIHIP (Hip Circumference Comment)
**# Be SUPER careful to exclude cases from which data could not be obtained (when regarded as outcome)**




** Used as a exclusion criteria/to calculate a score before deleting the attribute

# Defining some functions
"""

#%% Defining a function to remove indices (rows) based on an exclusing criterion

def exclusion_criteria(df, index_excl_codes):
    modified_df = df.copy()
    for column_name, exclusion_criteria in index_excl_codes:
        try:
            modified_df = modified_df[~df[column_name].isin(exclusion_criteria)]
        except KeyError:
            print(f'Column {column_name} not found in the dataset.')
    return modified_df

#%% Defining the saving function

def save_dataset_excel(df,file_path, index = False):
  try:
    df.to_excel(file_path, index=index)
    print(f'Successfully saved to {file_path}')
  except Exception as e:
    print(f'error{str(e)}')

#%% Defining a function that will return 'NaN' whenever the denominator is zero (to prevent the production of infinite numbers when dividing two numbers)
def safe_division(numerator, denominator):
  if denominator == 0:
    return np.nan
  else:
    return numerator / denominator

#%% Defining a function to calculate the mean (** it returns NaN whenever there's a missing value in either of the columns**)

def custom_mean(row,col_1,col_2):
  if pd.isnull(row[col_1]) or pd.isnull(row[col_2]):
    return np.nan
  else:
    return row[[col_1,col_2]].mean()

"""# Exclusion criteria"""

# @title Removing subjects based on the exclusion criteria

index_excl_codes = [
    ('RIDEXPRG' , [1]), # Removing the pregnant subjects
    ('BMIWT', [1,4]),   # Excluding subjects with code=1 (weight not obtained) and code=4 (subjects' weights were measured when a 'medical appliance' was attached to  them) of BMIWT
                        # Note: Preliminary analyses showed that having a medical appliance (code = 4) seem to overestimate the BMI measurements
    ('BMIHT', [1,3]),  # Excluding subjects with code=1 (height not obtained) and code=3 (not straight) of BMIHT
    ('DPQ010', [7,9]), # Excluding subjects who refused to answer (code = 7) or replied 'don't know' (code = 9) to PHQ-9 questionnaire (depression)
    ('DPQ020', [7,9]),
    ('DPQ030', [7,9]),
    ('DPQ040', [7,9]),
    ('DPQ050', [7,9]),
    ('DPQ060', [7,9]),
    ('DPQ070', [7,9]),
    ('DPQ080', [7,9]),
    ('DPQ090', [7,9]),
    ('DPQ100', [7,9]),
    ('DR1DRSTZ', [2,5]), # Excluding subjects with code=2 (unreliable dietary data) and code=5 (dietary data was not obtained(days 1 and 2))
    ('DR2DRSTZ', [2,5]),  # Due to remarkable number of fallouts, two sets of datasets were created (one which includes valid subjects who completed day 1 of
                          # of dietary questionnaire and another one which includes the subjects with valid information for both days).
    ('MCQ160B', [1]), # Excluding subjects with a history of congestive heart failure
]

# Removing the cases having the exclusion criteria and producing the modified dataset

df_modified_excl = exclusion_criteria(crude_dataset, index_excl_codes)
df_modified_excl

"""# Exploring some variables"""

# Commented out IPython magic to ensure Python compatibility.
# 
# %%capture
# #%% Exploring the variables
# 
# 
# # df_modified_excl['RIDEXPRG'].describe()
# # df_modified_excl['BMIWT'].describe()
# # df_modified_excl['BMIHT'].describe()
# # df_modified_excl['DPQ100'].describe()
# # df_modified_excl['DPQ100'].isnull().sum()
# # df_modified_excl['PAD615'].isnull().sum()
# # count_1 = (df_modified_excl['MCQ160B']==1).sum()
# # count_1
#

#%% Calculating the depression score (PHQ-9)

# @title Calculating the depression score (PHQ-9)
#%%% The codes are adjusted so that missing values are not summed up #%%%

depression_vars = ['DPQ010','DPQ020','DPQ030','DPQ040','DPQ050','DPQ060','DPQ070','DPQ080','DPQ090','DPQ100']
df_modified_excl['Depression_total'] = np.where(df_modified_excl[depression_vars].notna().all(axis=1), df_modified_excl[depression_vars].sum(axis=1), np.nan)



# print((df_modified_excl['Depression_total'].isnull().sum()) / len(df_modified_excl) * 100)

#%% Slicing the dietary dataframe

# @title Slicing the dietary dataframe

# diet_df = df_modified_excl[['DR1TKCAL','DR1TPROT','DR1TCARB','DR1TSUGR','DR1TFIBE','DR1TTFAT','DR1TSFAT','DR1TMFAT','DR1TPFAT','DR1_320Z','DR2TKCAL',
# 'DR2TPROT','DR2TCARB','DR2TSUGR','DR2TFIBE','DR2TTFAT','DR2TSFAT','DR2TMFAT','DR2TPFAT','DR2TCHOL','DR2_320Z','DR1T_F_TOTAL', 'DR1T_F_CITMLB',
# 'DR1T_F_OTHER', 'DR1T_F_JUICE', 'DR1T_V_TOTAL', 'DR1T_V_DRKGR', 'DR1T_V_REDOR_TOTAL', 'DR1T_V_REDOR_TOMATO', 'DR1T_V_REDOR_OTHER', 'DR1T_V_STARCHY_TOTAL',
# 'DR1T_V_STARCHY_POTATO', 'DR1T_V_STARCHY_OTHER', 'DR1T_V_OTHER', 'DR1T_V_LEGUMES', 'DR1T_G_TOTAL', 'DR1T_G_WHOLE', 'DR1T_G_REFINED', 'DR1T_PF_TOTAL',
# 'DR1T_PF_MPS_TOTAL', 'DR1T_PF_MEAT', 'DR1T_PF_CUREDMEAT', 'DR1T_PF_ORGAN', 'DR1T_PF_POULT', 'DR1T_PF_SEAFD_HI', 'DR1T_PF_SEAFD_LOW', 'DR1T_PF_EGGS',
# 'DR1T_PF_SOY', 'DR1T_PF_NUTSDS', 'DR1T_PF_LEGUMES', 'DR1T_D_TOTAL', 'DR1T_D_MILK', 'DR1T_D_YOGURT', 'DR1T_D_CHEESE', 'DR1T_OILS', 'DR1T_SOLID_FATS',
# 'DR1T_ADD_SUGARS','DR1T_A_DRINKS', 'DR2TNUMF', 'DR2T_F_TOTAL', 'DR2T_F_CITMLB', 'DR2T_F_OTHER', 'DR2T_F_JUICE', 'DR2T_V_TOTAL', 'DR2T_V_DRKGR',
# 'DR2T_V_REDOR_TOTAL', 'DR2T_V_REDOR_TOMATO', 'DR2T_V_REDOR_OTHER', 'DR2T_V_STARCHY_TOTAL', 'DR2T_V_STARCHY_POTATO', 'DR2T_V_STARCHY_OTHER',
# 'DR2T_V_OTHER', 'DR2T_V_LEGUMES', 'DR2T_G_TOTAL', 'DR2T_G_WHOLE', 'DR2T_G_REFINED', 'DR2T_PF_TOTAL', 'DR2T_PF_MPS_TOTAL', 'DR2T_PF_MEAT',
# 'DR2T_PF_CUREDMEAT', 'DR2T_PF_ORGAN', 'DR2T_PF_POULT', 'DR2T_PF_SEAFD_HI', 'DR2T_PF_SEAFD_LOW', 'DR2T_PF_EGGS', 'DR2T_PF_SOY', 'DR2T_PF_NUTSDS',
# 'DR2T_PF_LEGUMES', 'DR2T_D_TOTAL', 'DR2T_D_MILK', 'DR2T_D_YOGURT', 'DR2T_D_CHEESE', 'DR2T_OILS', 'DR2T_SOLID_FATS', 'DR2T_ADD_SUGARS', 'DR2T_A_DRINKS',
# 'DR1TSODI', 'DR2TSODI']]

# diet_df.set_index(df_modified_excl['SEQN'], inplace=True)
# diet_df

"""# HEI Calculation"""

#%% Calculating some components needed for HEI-2020

# @title Calculating some components needed for HEI-2020

## To refernce the method used:
## https://epi.grants.cancer.gov/hei/hei-scoring-method.html#:~:text=To%20convert%20to%20a%20percent%20of%20calories%20basis%2C,to%20kcal%2C%20prior%20to%20dividing%20by%20total%20energy.
##!! 'Whole fruit' is calculated differently from NCI method; however, the results were verified and are identical

# Whole Fruit
Whole_Fruit_D1 = (df_modified_excl['DR1T_F_TOTAL'] - df_modified_excl['DR1T_F_JUICE']) # Total fruit minus fruit juices (Day1) (cup eq.)
df_modified_excl['Whole_Fruit_D1'] = Whole_Fruit_D1
Whole_Fruit_D2 = (df_modified_excl['DR2T_F_TOTAL'] - df_modified_excl['DR2T_F_JUICE'])
df_modified_excl['Whole_Fruit_D2'] = Whole_Fruit_D2

# Total vegetables
Total_Veg_incl_legumes_D1 = df_modified_excl['DR1T_V_TOTAL'] + df_modified_excl['DR1T_V_LEGUMES'] # Total vegetables calculated as FPED total veg. plus legumes counted as vegetables (Day1) (cup eq.)
df_modified_excl['Total_Veg_incl_legumes_D1'] = Total_Veg_incl_legumes_D1
Total_Veg_incl_legumes_D2 = df_modified_excl['DR2T_V_TOTAL'] + df_modified_excl['DR2T_V_LEGUMES']
df_modified_excl['Total_Veg_incl_legumes_D2'] = Total_Veg_incl_legumes_D2

# Dark greens and beans
Dark_Greens_and_Beans_D1 =  df_modified_excl['DR1T_V_DRKGR'] + df_modified_excl['DR1T_V_LEGUMES'] # Dark Green vegetables plus legumes counted as vegetables (Day1) (cup eq.)
df_modified_excl['Dark_Greens_and_Beans_D1'] = Dark_Greens_and_Beans_D1
Dark_Greens_and_Beans_D2 =  df_modified_excl['DR2T_V_DRKGR'] + df_modified_excl['DR2T_V_LEGUMES']
df_modified_excl['Dark_Greens_and_Beans_D2'] = Dark_Greens_and_Beans_D2

# Total protein
Total_Protein_D1 = df_modified_excl['DR1T_PF_TOTAL'] + df_modified_excl['DR1T_PF_LEGUMES'] # Total meat, poultry, seafood, organ meats, cured meat, eggs, soy, and nuts and seeds; excludes legumes (oz. eq.)
# + Legumes computed as protein foods (oz. eq.)
df_modified_excl['Total_Protein_D1'] = Total_Protein_D1
Total_Protein_D2 = df_modified_excl['DR2T_PF_TOTAL'] + df_modified_excl['DR2T_PF_LEGUMES']
df_modified_excl['Total_Protein_D2'] = Total_Protein_D2

# Seafood and plant proteins
Seafood_and_plant_proteins_D1 = df_modified_excl['DR1T_PF_SEAFD_HI'] + df_modified_excl['DR1T_PF_SEAFD_LOW'] + df_modified_excl['DR1T_PF_SOY'] + df_modified_excl['DR1T_PF_NUTSDS'] + df_modified_excl['DR1T_PF_LEGUMES']
# Seafood (finfish, shellfish and other seafood) high in n-3 fatty acids (oz. eq.) + Seafood (finfish, shellfish and other seafood) low in n-3 fatty acids (oz. eq.)
# + Soy products, excluding calcium fortified soy milk and immature soybeans (oz. eq.) + Peanuts, tree nuts, and seeds, excludes coconut (oz. eq.)
# + Legumes computed as protein foods (oz. eq.)
df_modified_excl ['Seafood_and_plant_proteins_D1'] = Seafood_and_plant_proteins_D1
Seafood_and_plant_proteins_D2 = df_modified_excl['DR2T_PF_SEAFD_HI'] + df_modified_excl['DR2T_PF_SEAFD_LOW'] + df_modified_excl['DR2T_PF_SOY'] + df_modified_excl['DR2T_PF_NUTSDS'] + df_modified_excl['DR2T_PF_LEGUMES']
df_modified_excl ['Seafood_and_plant_proteins_D2'] = Seafood_and_plant_proteins_D2



# Fatty acids
PUFA_MUFA_D1 = (df_modified_excl['DR1TPFAT'] + df_modified_excl['DR1TMFAT']) # PUFA + MUFA (d1)
df_modified_excl['PUFA_MUFA_D1'] = PUFA_MUFA_D1
# print(df_modified_excl['PUFA_MUFA_D1'].describe())
df_modified_excl['Fatty_acids_D1'] = df_modified_excl.apply(lambda row: safe_division(row['PUFA_MUFA_D1'], row['DR1TSFAT']), axis=1).round(2)
# print(df_modified_excl['Fatty_acids_D1'].describe())
PUFA_MUFA_D2 = (df_modified_excl['DR2TPFAT'] + df_modified_excl['DR2TMFAT']) # PUFA + MUFA (d2)
df_modified_excl['PUFA_MUFA_D2'] = PUFA_MUFA_D2
# print(df_modified_excl['PUFA_MUFA_D2'].describe())
df_modified_excl['Fatty_acids_D2'] = df_modified_excl.apply(lambda row: safe_division(row['PUFA_MUFA_D2'], row['DR2TSFAT']), axis=1).round(2)
# print(df_modified_excl['Fatty_acids_D2'].describe())





# Sodium (in grams)
Sodium_D1 = df_modified_excl['DR1TSODI'] / 1000
df_modified_excl['Sodium_D1'] = Sodium_D1
Sodium_D2 = df_modified_excl['DR2TSODI'] / 1000
df_modified_excl['Sodium_D2'] = Sodium_D2

modified_df_hei = df_modified_excl.copy()
modified_df_hei

#%% Calculating the energy-adjusted (in 1000 Cal energy intake) components

# @title Calculating the energy-adjusted (in 1000 Cal energy intake) components



# Total Fruit
Total_fruit_EA_d1 = ((modified_df_hei['DR1T_F_TOTAL'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Total_fruit_EA_d1'] = Total_fruit_EA_d1
Total_fruit_EA_d2 = ((modified_df_hei['DR2T_F_TOTAL'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Total_fruit_EA_d2'] = Total_fruit_EA_d2


# Whole Fruit
Whole_fruit_EA_d1 = ((modified_df_hei['Whole_Fruit_D1'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Whole_fruit_EA_d1'] = Whole_fruit_EA_d1
Whole_fruit_EA_d2 = ((modified_df_hei['Whole_Fruit_D2'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Whole_fruit_EA_d2'] = Whole_fruit_EA_d2

# Total Vegetables
Total_veg_EA_d1 = ((modified_df_hei['Total_Veg_incl_legumes_D1'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Total_veg_EA_d1'] = Total_veg_EA_d1
Total_veg_EA_d2 = ((modified_df_hei['Total_Veg_incl_legumes_D2'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Total_veg_EA_d2'] = Total_veg_EA_d2

# Greans and Beans
Greens_Beans_EA_d1 = ((modified_df_hei['Dark_Greens_and_Beans_D1'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Greens_Beans_EA_d1'] = Greens_Beans_EA_d1
Greens_Beans_EA_d2 = ((modified_df_hei['Dark_Greens_and_Beans_D2'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Greens_Beans_EA_d2'] = Greens_Beans_EA_d2

# Whole Grains
Whole_grains_EA_d1 = ((modified_df_hei['DR1T_G_WHOLE'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Whole_grains_EA_d1'] = Whole_grains_EA_d1
Whole_grains_EA_d2 = ((modified_df_hei['DR2T_G_WHOLE'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Whole_grains_EA_d2'] = Whole_grains_EA_d2

# Dairy
Dairy_EA_d1 = ((modified_df_hei['DR1T_D_TOTAL'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Dairy_EA_d1'] = Dairy_EA_d1
Dairy_EA_d2 = ((modified_df_hei['DR2T_D_TOTAL'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Dairy_EA_d2'] = Dairy_EA_d2

# Total Protein
Total_protein_EA_d1 = ((modified_df_hei['Total_Protein_D1'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Total_protein_EA_d1'] = Total_protein_EA_d1
Total_protein_EA_d2 = ((modified_df_hei['Total_Protein_D2'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Total_protein_EA_d2'] = Total_protein_EA_d2

# Seafood and Plant Proteins
Seafood_and_plant_EA_d1 = ((modified_df_hei['Seafood_and_plant_proteins_D1'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Seafood_and_plant_EA_d1'] = Seafood_and_plant_EA_d1
Seafood_and_plant_EA_d2 = ((modified_df_hei['Seafood_and_plant_proteins_D2'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Seafood_and_plant_EA_d2'] = Seafood_and_plant_EA_d2

# Refined Grains
Refined_grain_EA_d1 = ((modified_df_hei['DR1T_G_REFINED'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
modified_df_hei['Refined_grain_EA_d1'] = Refined_grain_EA_d1
Refined_grain_EA_d2 = ((modified_df_hei['DR2T_G_REFINED'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
modified_df_hei['Refined_grain_EA_d2'] = Refined_grain_EA_d2

# Sodium
# Sodium_EA_d1 = ((modified_df_hei['Sodium_D1'] / modified_df_hei['DR1TKCAL'])*1000).round(2)
Sodium_EA_d1 = ((modified_df_hei.apply(lambda row: safe_division(row['Sodium_D1'], row['DR1TKCAL']), axis=1))*1000).round(2)
modified_df_hei['Sodium_EA_d1'] = Sodium_EA_d1
# Sodium_EA_d2 = ((modified_df_hei['Sodium_D2'] / modified_df_hei['DR2TKCAL'])*1000).round(2)
Sodium_EA_d2 = ((modified_df_hei.apply(lambda row: safe_division(row['Sodium_D2'], row['DR2TKCAL']), axis=1))*1000).round(2)
modified_df_hei['Sodium_EA_d2'] = Sodium_EA_d2

# Added Sugars
Added_sugar_percent_d1 = (((modified_df_hei['DR1T_ADD_SUGARS']*16) / modified_df_hei['DR1TKCAL'])*100).round(2) # Refer to NCI (link in the preceding code) (Each tsp eq. of added sugar yields 16 kcal energy)
modified_df_hei['Added_sugar_percent_d1'] = Added_sugar_percent_d1
Added_sugar_percent_d2 = (((modified_df_hei['DR2T_ADD_SUGARS']*16) / modified_df_hei['DR2TKCAL'])*100).round(2)
modified_df_hei['Added_sugar_percent_d2'] = Added_sugar_percent_d2


# Saturated Fats
Saturated_fat_percent_d1 = (((modified_df_hei['DR1TSFAT']*9) / modified_df_hei['DR1TKCAL'])*100).round(2)
modified_df_hei['Saturated_fat_percent_d1'] = Saturated_fat_percent_d1
Saturated_fat_percent_d2 = (((modified_df_hei['DR2TSFAT']*9) / modified_df_hei['DR2TKCAL'])*100).round(2)
modified_df_hei['Saturated_fat_percent_d2'] = Saturated_fat_percent_d2




# row_num_2 = len(modified_df_hei)
# print(modified_df_hei['Sodium_EA_d1'].describe())
# print(modified_df_hei['Sodium_EA_d1'].isnull().sum())
# print(((modified_df_hei['Sodium_EA_d1'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Sodium_EA_d2'].describe())
# print(modified_df_hei['Sodium_EA_d2'].isnull().sum())
# print(((modified_df_hei['Sodium_EA_d2'].isnull().sum() / row_num_2) * 100).round(2))

#%%Calculating the mean of 2-day intake of **energy-adjusted** HEI components

# @title Calculating the mean of 2-day intake of **energy-adjusted** HEI components

###*** The first calculation functions in a way that if there is a missing value, then the only existing one (the one with non-missing) will be output***###

# # Total Fruit
## modified_df_hei['Total_fruit_mean'] = (modified_df_hei[['Total_fruit_EA_d1', 'Total_fruit_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Total_fruit_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Total_fruit_EA_d1', 'Total_fruit_EA_d2'), axis=1).round(2)

# # Whole Fruit
## modified_df_hei['Whole_fruit_mean'] = (modified_df_hei[['Whole_fruit_EA_d1', 'Whole_fruit_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Whole_fruit_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Whole_fruit_EA_d1', 'Whole_fruit_EA_d2'), axis=1).round(2)

# # Total Vegetables
# modified_df_hei['Total_veg_mean'] = (modified_df_hei[['Total_veg_EA_d1', 'Total_veg_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Total_veg_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Total_veg_EA_d1', 'Total_veg_EA_d2'), axis=1).round(2)

# # Greens and Beans
# modified_df_hei['Green_bean_mean'] = (modified_df_hei[['Greens_Beans_EA_d1', 'Greens_Beans_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Green_bean_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Greens_Beans_EA_d1', 'Greens_Beans_EA_d2'), axis=1).round(2)

# # Whole Grains
# modified_df_hei['Whole_grains_mean'] = (modified_df_hei[['Whole_grains_EA_d1', 'Whole_grains_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Whole_grains_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Whole_grains_EA_d1', 'Whole_grains_EA_d2'), axis=1).round(2)

# # Dairy
# modified_df_hei['Dairy_mean'] = (modified_df_hei[['Dairy_EA_d1', 'Dairy_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Dairy_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Dairy_EA_d1', 'Dairy_EA_d2'), axis=1).round(2)

# # Total Protein Foods
# modified_df_hei['Total_protein_mean'] = (modified_df_hei[['Total_protein_EA_d1', 'Total_protein_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Total_protein_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Total_protein_EA_d1', 'Total_protein_EA_d2'), axis=1).round(2)

# # Seafood and Plant Proteins
# modified_df_hei['Seafood_plant_protein_mean'] = (modified_df_hei[['Seafood_and_plant_EA_d1', 'Seafood_and_plant_EA_d1']].mean(axis = 1)).round(2)
modified_df_hei['Seafood_plant_protein_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Seafood_and_plant_EA_d1', 'Seafood_and_plant_EA_d1'), axis=1).round(2)

# # Fatty Acids
# modified_df_hei['Fatty_acids_mean'] = (modified_df_hei[['Fatty_acids_D1', 'Fatty_acids_D2']].mean(axis = 1)).round(2)
modified_df_hei['Fatty_acids_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Fatty_acids_D1', 'Fatty_acids_D2'), axis=1).round(2)



# # Refined Grains
# modified_df_hei['Refined_grain_mean'] = (modified_df_hei[['Refined_grain_EA_d1', 'Refined_grain_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Refined_grain_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Refined_grain_EA_d1', 'Refined_grain_EA_d2'), axis=1).round(2)

# # Sodium
# modified_df_hei['Sodium_mean'] = (modified_df_hei[['Sodium_EA_d1', 'Sodium_EA_d2']].mean(axis = 1)).round(2)
modified_df_hei['Sodium_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Sodium_EA_d1', 'Sodium_EA_d2'), axis=1).round(2)

# # Added Sugar
# modified_df_hei['Added_sugar_mean'] = (modified_df_hei[['Added_sugar_percent_d1', 'Added_sugar_percent_d2']].mean(axis = 1)).round(2)
modified_df_hei['Added_sugar_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Added_sugar_percent_d1', 'Added_sugar_percent_d2'), axis=1).round(2)

# # Saturated Fat
# modified_df_hei['Saturated_fat_mean'] = (modified_df_hei[['Saturated_fat_percent_d1', 'Saturated_fat_percent_d2']].mean(axis = 1)).round(2)
modified_df_hei['Saturated_fat_mean'] = modified_df_hei.apply(lambda row: custom_mean(row, 'Saturated_fat_percent_d1', 'Saturated_fat_percent_d2'), axis=1).round(2)

print(modified_df_hei.columns)

# @title Further investigating  of the built variables


# print((modified_df_hei['Sodium_EA_d1'] == np.inf).sum())
# print((modified_df_hei['Sodium_EA_d2'] == np.inf).sum())
# print((modified_df_hei['Sodium_mean'] == np.inf).sum())

# inf_rows = modified_df_hei['Sodium_mean'] == np.inf
# print(modified_df_hei.loc[inf_rows, ['Sodium_EA_d1', 'Sodium_EA_d2']])


# row_num_1 = len(df_modified_excl)
# row_num_2 = len(modified_df_hei)

# # print(df_modified_excl[''].describe())
# # print(df_modified_excl[''].isnull().sum())
# # print(((df_modified_excl[''].isnull().sum() / row_num) * 100).round(2))  # Missing Percentage

# # print(modified_df_hei[''].describe())
# # print(modified_df_hei[''].isnull().sum())
# # print(((modified_df_hei[''].isnull().sum() / row_num) * 100).round(2))  # Missing Percentage


# # df_modified_excl['Depression_total'].describe()
# # df_modified_excl['Depression_total'].isnull().sum()
# # df_modified_excl['Depression_total'].isnull().sum() / row_num * 100
# # df_modified_excl['PA_vigorous_total'].describe()
# # df_modified_excl['PA_vigorous_total'].isnull().sum() / row_num * 100            ### More that 91% missing value in vigorous PA !!! ###
# # df_modified_excl['Whole_Fruit_D1'].describe()
# # df_modified_excl['Whole_Fruit_D1'].isnull().sum()
# # df_modified_excl['Whole_Fruit_D1'].isnull().sum() / row_num * 100   # Missing Percentage
# # print(df_modified_excl['Whole_Fruit_D1'].describe())
# # print(df_modified_excl['DR1T_F_TOTAL'].describe())

# print(modified_df_hei['Total_fruit_mean'].describe())
# print(modified_df_hei['Total_fruit_mean'].isnull().sum())
# print(((modified_df_hei['Total_fruit_mean'].isnull().sum() / row_num_2) * 100).round(2))  # Missing Percentage

# print(modified_df_hei['Whole_fruit_mean'].describe())
# print(modified_df_hei['Whole_fruit_mean'].isnull().sum())
# print(((modified_df_hei['Whole_fruit_mean'].isnull().sum() / row_num_2) * 100).round(2))  # Missing Percentage

# print(modified_df_hei['Total_veg_mean'].describe())
# print(modified_df_hei['Total_veg_mean'].isnull().sum())
# print(((modified_df_hei['Total_veg_mean'].isnull().sum() / row_num_2) * 100).round(2))  # Missing Percentage

# print(modified_df_hei['Green_bean_mean'].describe())
# print(modified_df_hei['Green_bean_mean'].isnull().sum())
# print(((modified_df_hei['Green_bean_mean'].isnull().sum() / row_num_2) * 100).round(2))  # Missing Percentage

# print(modified_df_hei['Whole_grains_mean'].describe())
# print(modified_df_hei['Whole_grains_mean'].isnull().sum())
# print(((modified_df_hei['Whole_grains_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Dairy_mean'].describe())
# print(modified_df_hei['Dairy_mean'].isnull().sum())
# print(((modified_df_hei['Dairy_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Total_protein_mean'].describe())
# print(modified_df_hei['Total_protein_mean'].isnull().sum())
# print(((modified_df_hei['Total_protein_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Seafood_plant_protein_mean'].describe())
# print(modified_df_hei['Seafood_plant_protein_mean'].isnull().sum())
# print(((modified_df_hei['Seafood_plant_protein_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Fatty_acids_mean'].describe())
# print(modified_df_hei['Fatty_acids_mean'].isnull().sum())
# print(((modified_df_hei['Fatty_acids_mean'].isnull().sum() / row_num_2) * 100).round(2))


# print(modified_df_hei['Refined_grain_mean'].describe())
# print(modified_df_hei['Refined_grain_mean'].isnull().sum())
# print(((modified_df_hei['Refined_grain_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Refined_grain_EA_d1'].describe())
# print(modified_df_hei['Refined_grain_EA_d1'].isnull().sum())
# print(((modified_df_hei['Refined_grain_EA_d1'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Refined_grain_EA_d2'].describe())
# print(modified_df_hei['Refined_grain_EA_d2'].isnull().sum())
# print(((modified_df_hei['Refined_grain_EA_d2'].isnull().sum() / row_num_2) * 100).round(2))



# print(modified_df_hei['Sodium_mean'].describe())
# print(modified_df_hei['Sodium_mean'].isnull().sum())
# print(((modified_df_hei['Sodium_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Sodium_D1'].describe())
# print(modified_df_hei['Sodium_D1'].isnull().sum())
# print(((modified_df_hei['Sodium_D1'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Sodium_D2'].describe())
# print(modified_df_hei['Sodium_D2'].isnull().sum())
# print(((modified_df_hei['Sodium_D2'].isnull().sum() / row_num_2) * 100).round(2))



# print(modified_df_hei['Added_sugar_mean'].describe())
# print(modified_df_hei['Added_sugar_mean'].isnull().sum())
# print(((modified_df_hei['Added_sugar_mean'].isnull().sum() / row_num_2) * 100).round(2))

# print(modified_df_hei['Saturated_fat_mean'].describe())
# print(modified_df_hei['Saturated_fat_mean'].isnull().sum())
# print(((modified_df_hei['Saturated_fat_mean'].isnull().sum() / row_num_2) * 100).round(2))




# print(modified_df_hei['Fatty_acids_mean'].describe())
# print(modified_df_hei['Fatty_acids_mean'].isnull().sum())
# print(((modified_df_hei['Fatty_acids_mean'].isnull().sum() / row_num_2) * 100).round(2))  # Missing Percentage

# @title Redefining the food group information to be used in HEI-2020


from tables.table import Column

from sklearn.impute import KNNImputer
imputer_diet = KNNImputer(n_neighbors=2)


HEI_dataset = {
    'Total Fruits': modified_df_hei['Total_fruit_mean'],
    'Whole Fruits': modified_df_hei['Whole_fruit_mean'],
    'Total Vegetables': modified_df_hei['Total_veg_mean'],
    'Greens and Beans': modified_df_hei['Green_bean_mean'],
    'Whole Grains': modified_df_hei['Whole_grains_mean'],
    'Dairy': modified_df_hei['Dairy_mean'],
    'Total Protein Foods': modified_df_hei['Total_protein_mean'],
    'Seafood and Plant Proteins': modified_df_hei['Seafood_plant_protein_mean'],
    'Fatty Acids Ratio (PUFAs + MUFAs)/SFAs': modified_df_hei['Fatty_acids_mean'],
    "Refined Grains" : modified_df_hei['Refined_grain_mean'],
    "Sodium" : modified_df_hei['Sodium_mean'],
    "Added Sugars" : modified_df_hei['Added_sugar_mean'],
    "Saturated Fats" : modified_df_hei['Saturated_fat_mean']
}

HEI_dataset_df = pd.DataFrame(HEI_dataset)
HEI_dataset_df
HEI_dataset_imput = imputer_diet.fit_transform(HEI_dataset_df)
HEI_dataset_df_imput = pd.DataFrame(HEI_dataset_imput, columns=['Total Fruits','Whole Fruits','Total Vegetables','Greens and Beans','Whole Grains',
'Dairy','Total Protein Foods','Seafood and Plant Proteins','Fatty Acids Ratio (PUFAs + MUFAs)/SFAs',"Refined Grains","Sodium","Added Sugars","Saturated Fats"]
)
HEI_dataset_df_imput.index = HEI_dataset_df.index
HEI_dataset_df_imput

# @title HEI-2020 function

import pandas as pd
import numpy as np


def calculate_hei_2020(df):
    # Define the standards for maximum and minimum scores
    standards = {
        'Total Fruits': {'max': 0.8, 'min': 0, 'max_points': 5, 'adequacy': True},
        'Whole Fruits': {'max': 0.4, 'min': 0, 'max_points': 5, 'adequacy': True},
        'Total Vegetables': {'max': 1.1, 'min': 0, 'max_points': 5, 'adequacy': True},
        'Greens and Beans': {'max': 0.2, 'min': 0, 'max_points': 5, 'adequacy': True},
        'Whole Grains': {'max': 1.5, 'min': 0, 'max_points': 10, 'adequacy': True},
        'Dairy': {'max': 1.3, 'min': 0, 'max_points': 10, 'adequacy': True},
        'Total Protein Foods': {'max': 2.5, 'min': 0, 'max_points': 5, 'adequacy': True},
        'Seafood and Plant Proteins': {'max': 0.8, 'min': 0, 'max_points': 5, 'adequacy': True},
        'Fatty Acids Ratio (PUFAs + MUFAs)/SFAs': {'max' :2.5 , 'min' :1.2 , 'max_points' :10 , 'adequacy' : True},

        # Moderation components

        "Refined Grains" : {"max" :1.8 , "min" :4.3 , "max_points" :10 , "adequacy" : False },
        "Sodium" : {"max" :1.1 , "min" :2.0 , "max_points" :10 , "adequacy" : False },
        "Added Sugars" : {"max" :6.5 , "min" :26 , "max_points" :10 , "adequacy" : False },
        "Saturated Fats" : {"max" :8 , "min" :16 , "max_points" :10 , "adequacy" : False }
    }

    # Initialize an empty DataFrame to store the scores
    scores = pd.DataFrame(index=df.index)

    # Calculate scores for each component
    for component in standards.keys():
        max_val = standards[component]['max']
        min_val = standards[component]['min']
        max_points = standards[component]['max_points']
        adequacy = standards[component]['adequacy']

        if adequacy:
            # For adequacy components: higher intake -> higher score
            scores[component] = ((df[component] - min_val) / (max_val - min_val)) * max_points
        else:
            # For moderation components: higher intake -> lower score
            scores[component] = max_points - ((df[component] - max_val) / (min_val - max_val)) * max_points

        # Ensure that scores are within the range [0,max_points]
        scores[component] = np.clip(scores[component], 0, max_points)

    # Sum up the scores to get the final HEI-2015 score
    scores['HEI-2020'] = scores.sum(axis=1)

    return scores

# @title HEI-2020 calculation (** Missing values are regarded as means of the column** (i.e Testing the function)**)

# #If you want to test again, replace 'scores['HEI-2020'] = scores.sum(axis=1)' with 'scores['HEI-2020'] = scores.fillna(np.mean).sum(axis=1)' in the function # #

# HEI_2020_test = calculate_hei_2020(HEI_dataset_df).round(2)
# HEI_2020_test
# print(HEI_2020_test.describe())

# @title HEI-2020 calculation (**Missing values filled using KNNimputer**)

# #%% HEI-2020 calculation (** Missing values filled using KNNimputer**)
HEI_2020_test_KNN = calculate_hei_2020(HEI_dataset_df_imput).round(2)
HEI_2020_test_KNN
# print(HEI_2020_test_KNN.describe())

# @title Concatenation of the HEI-2020 dataset with the previous dataset
#%% Concatenation of the HEI-2020 dataset with the previous dataset

modified_df_1 = pd.concat([modified_df_hei,HEI_2020_test_KNN], axis=1)
modified_df_1

"""# Dropping the unnecessary variables"""

# @title Deleting the variables used to estimate HEI-2020 score

#%% Deleting the variables used to estimate HEI-2020 score

modified_df_2 = modified_df_1.drop(columns = ['DR1_320Z','DR2_320Z','DR1T_F_TOTAL', 'DR1T_F_CITMLB',
'DR1T_F_OTHER', 'DR1T_F_JUICE', 'DR1T_V_TOTAL', 'DR1T_V_DRKGR', 'DR1T_V_REDOR_TOTAL', 'DR1T_V_REDOR_TOMATO', 'DR1T_V_REDOR_OTHER', 'DR1T_V_STARCHY_TOTAL',
'DR1T_V_STARCHY_POTATO', 'DR1T_V_STARCHY_OTHER', 'DR1T_V_OTHER', 'DR1T_V_LEGUMES', 'DR1T_G_TOTAL', 'DR1T_G_WHOLE', 'DR1T_G_REFINED', 'DR1T_PF_TOTAL',
'DR1T_PF_MPS_TOTAL', 'DR1T_PF_MEAT', 'DR1T_PF_CUREDMEAT', 'DR1T_PF_ORGAN', 'DR1T_PF_POULT', 'DR1T_PF_SEAFD_HI', 'DR1T_PF_SEAFD_LOW', 'DR1T_PF_EGGS',
'DR1T_PF_SOY', 'DR1T_PF_NUTSDS', 'DR1T_PF_LEGUMES', 'DR1T_D_TOTAL', 'DR1T_D_MILK', 'DR1T_D_YOGURT', 'DR1T_D_CHEESE', 'DR1T_OILS', 'DR1T_SOLID_FATS',
'DR1T_ADD_SUGARS', 'DR2TNUMF', 'DR2T_F_TOTAL', 'DR2T_F_CITMLB', 'DR2T_F_OTHER', 'DR2T_F_JUICE', 'DR2T_V_TOTAL', 'DR2T_V_DRKGR',
'DR2T_V_REDOR_TOTAL', 'DR2T_V_REDOR_TOMATO', 'DR2T_V_REDOR_OTHER', 'DR2T_V_STARCHY_TOTAL', 'DR2T_V_STARCHY_POTATO', 'DR2T_V_STARCHY_OTHER',
'DR2T_V_OTHER', 'DR2T_V_LEGUMES', 'DR2T_G_TOTAL', 'DR2T_G_WHOLE', 'DR2T_G_REFINED', 'DR2T_PF_TOTAL', 'DR2T_PF_MPS_TOTAL', 'DR2T_PF_MEAT',
'DR2T_PF_CUREDMEAT', 'DR2T_PF_ORGAN', 'DR2T_PF_POULT', 'DR2T_PF_SEAFD_HI', 'DR2T_PF_SEAFD_LOW', 'DR2T_PF_EGGS', 'DR2T_PF_SOY', 'DR2T_PF_NUTSDS',
'DR2T_PF_LEGUMES', 'DR2T_D_TOTAL', 'DR2T_D_MILK', 'DR2T_D_YOGURT', 'DR2T_D_CHEESE', 'DR2T_OILS', 'DR2T_SOLID_FATS', 'DR2T_ADD_SUGARS', 'DR2T_A_DRINKS',
'DR1TSODI', 'DR2TSODI', 'Whole_Fruit_D1', 'Whole_Fruit_D2', 'Total_Veg_incl_legumes_D1', 'Total_Veg_incl_legumes_D2', 'Dark_Greens_and_Beans_D1', 'Dark_Greens_and_Beans_D2',
'Total_Protein_D1', 'Total_Protein_D2', 'Seafood_and_plant_proteins_D1', 'Seafood_and_plant_proteins_D2', 'PUFA_MUFA_D1', 'Fatty_acids_D1', 'PUFA_MUFA_D2',
'Fatty_acids_D2', 'Sodium_D1', 'Sodium_D2', 'Total_fruit_EA_d1', 'Total_fruit_EA_d2', 'Whole_fruit_EA_d1', 'Whole_fruit_EA_d2', 'Total_veg_EA_d1', 'Total_veg_EA_d2',
'Greens_Beans_EA_d1', 'Greens_Beans_EA_d2', 'Whole_grains_EA_d1', 'Whole_grains_EA_d2', 'Dairy_EA_d1', 'Dairy_EA_d2', 'Total_protein_EA_d1', 'Total_protein_EA_d2',
'Seafood_and_plant_EA_d1', 'Seafood_and_plant_EA_d2', 'Refined_grain_EA_d1', 'Refined_grain_EA_d2', 'Sodium_EA_d1', 'Sodium_EA_d2', 'Added_sugar_percent_d1',
'Added_sugar_percent_d2', 'Saturated_fat_percent_d1', 'Saturated_fat_percent_d2', 'Total_fruit_mean', 'Whole_fruit_mean', 'Total_veg_mean', 'Green_bean_mean',
'Whole_grains_mean', 'Dairy_mean', 'Total_protein_mean', 'Seafood_plant_protein_mean', 'Fatty_acids_mean', 'Refined_grain_mean', 'Sodium_mean', 'Added_sugar_mean',
'Saturated_fat_mean'])
modified_df_2

# @title Averaging the calorie, macronutrient and cholesterol intake
# (of individuals with two-day dietary recoreds)

modified_df_2['Calorie_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TKCAL', 'DR2TKCAL'), axis=1).round(2)
modified_df_2['Protein_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TPROT', 'DR2TPROT'), axis=1).round(2)
modified_df_2['Carb_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TCARB', 'DR2TCARB'), axis=1).round(2)
modified_df_2['Fat_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TTFAT', 'DR2TTFAT'), axis=1).round(2)
modified_df_2['Sugar_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TSUGR', 'DR2TSUGR'), axis=1).round(2)
modified_df_2['Fiber_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TFIBE', 'DR2TFIBE'), axis=1).round(2)
modified_df_2['SAFA_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TSFAT', 'DR2TSFAT'), axis=1).round(2)
modified_df_2['MUFA_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TMFAT', 'DR2TMFAT'), axis=1).round(2)
modified_df_2['PUFA_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TPFAT', 'DR2TPFAT'), axis=1).round(2)
modified_df_2['Cholesterol_intake_mean'] = modified_df_2.apply(lambda row: custom_mean(row, 'DR1TCHOL', 'DR2TCHOL'), axis=1).round(2)

# modified_df_hei

# @title Removing other unnecessary variables

#%% Removing other unnecessary variables

modified_df_3 = modified_df_2.drop(columns = ['RIDEXPRG', 'BMDSTATS', 'BMXWT', 'BMIWT', 'BMXHT', 'BMIHT', 'BMDBMIC', 'BPXOSY1',
                                              'BPXODI1', 'BPXOSY2', 'BPXODI2', 'BPXOSY3', 'BPXODI3', 'DIQ010', 'DIQ160',  'DPQ010',  'DPQ020',
                                              'DPQ030', 'DPQ040', 'DPQ050', 'DPQ060', 'DPQ070', 'DPQ080', 'DPQ090', 'DPQ100', 'DR1DRSTZ', 'DR2DRSTZ',
                                              'ECD010', 'ECD070B', 'ECQ080', 'ECQ090', 'MCQ160B', 'MCQ170M', 'MCQ170L', 'PAQ610', 'PAD615', 'PAQ625',
                                              'PAD630', 'PAQ640', 'PAD645', 'PAQ655', 'PAD660', 'PAQ670', 'PAD675', 'SLQ300', 'SLQ310', 'SLQ320', 'SLQ330',
                                              'BMXWAIST', 'BMIWAIST', 'BMXHIP', 'BMIHIP', 'WHQ060', 'WHD080A',  'WHD080B',  'WHD080C', 'WHD080D',
                                              'WHD080E', 'WHD080F', 'WHD080G', 'WHD080H', 'WHD080I', 'WHD080J', 'WHD080K','WHD080M', 'WHD080N',
                                              'WHD080O', 'WHD080P', 'WHD080Q', 'WHD080R', 'WHD080S','WHD080T', 'WHD080U', 'WHD080L', 'WHQ030M',
                                              'WHQ500', 'WHQ520', 'WHQ225', 'MCQ371A', 'MCQ371B', 'MCQ371C', 'MCQ371D', 'SDMVPSU', 'SDMVSTRA','DRABF', 'DRDINT', 'DR1TNUMF','DR1TKCAL', 'DR2TKCAL','DR1TPROT', 'DR2TPROT',
                                              'DR1TCARB', 'DR2TCARB', 'DR1TCHOL', 'DR2TCHOL', 'DR1TSUGR','DR1TFIBE','DR1TTFAT','DR1TSFAT',
                                              'DR1TMFAT','DR1TPFAT','DR2TSUGR','DR2TFIBE','DR2TTFAT','DR2TSFAT', 'DR2TMFAT','DR2TPFAT'])

# @title Deleting attributes with high number of missing values

from tables import indexes
# Defining the % of NaNs in the dataset

# missing_value_Prc = (modified_df_3.isnull().mean()*100).round(2)
# missing_value_Prc
# missing_data = pd.DataFrame({'Missing_percentage': missing_value_Prc})
# missing_data

#%% Counting the number of attributes with high missing
threshold = 0.5
missing_proportion = modified_df_3.isnull().mean()
high_missing_attributes = missing_proportion[missing_proportion >= threshold].index.tolist()
high_missing_attributes

# num_high_missing_attributes = len(columns_to_remove)
# num_high_missing_attributes

#%% Defininng a function which drops the attribute that have >= 50% missing

def excluding_invaluable_attributes (df, threshold = 0.5):
  copied_df = df.copy()
  missing_proportion = df.isnull().mean()
  columns_to_remove = missing_proportion[missing_proportion >= threshold].index.tolist()
  cleaned_df = copied_df.drop(columns = columns_to_remove)
  return cleaned_df


modified_df_4 = excluding_invaluable_attributes (modified_df_3)
modified_df_4
# print(modified_df_4['BMXBMI'].describe())

# @title Further removing of unnecessary variables (Either excessive or containing significant missing values)

#%% Further removing of unnecessary variables (Either excessive or containing significant missing values)

modified_df_5 = modified_df_4.drop(columns = ['RIDRETH1','ALQ130','CBQ880', 'CBQ581', 'CBQ695A', 'DBD100', 'DR1_300', 'DR2_300', 'OSQ230', 'WHD110',
                                              'WHD120', 'WHD140', 'WHQ150', 'WHD010' , 'WHD020', 'WHQ030', 'WHQ040', 'WHQ070'])
modified_df_5.loc[modified_df_5['PAD680']==9999, 'PAD680'] = np.nan
# modified_df_5.loc[modified_df_5['WHD010']==9999, 'WHD010'] = np.nan
# modified_df_5.loc[modified_df_5['WHD020']==9999, 'WHD020'] = np.nan
# modified_df_5.loc[modified_df_5['WHD020']==7777, 'WHD020'] = np.nan


modified_df_5
# print(modified_df_5['WHD020'].describe())

df_final = modified_df_5.copy()
df_final

"""# Preparing the dataset for machine learning (Stage 1)"""

# @title Defining BMI categories

#%% Defining BMI categories

df_final['BMI_cat'] = pd.cut(df_final['BMXBMI'],
                                   bins =[0,24.99,np.inf],
                                   labels = [0,1])

# @title Visualizing the distribution of BMI and gender in the population

#%% Visualizing the distribution of BMI and gender in the population

import matplotlib.pyplot as plt

fig, axs = plt.subplots(1,2, figsize = (8,6))
axs[0].hist(df_final['BMI_cat'], bins = 4, edgecolor = 'black')
axs[0].set_title('Ditribution of BMI categories')
axs[0].set_xlabel('BMI categories')
axs[0].set_ylabel('Count')

axs[1].hist(modified_df_5['RIAGENDR'], bins = 2, edgecolor = 'black')
axs[1].set_title('Ditribution of gender groups')
axs[1].set_xlabel('Gender')
axs[0].set_ylabel('Count')

plt.tight_layout()
plt.show()

# @title Visualizing the differences in outcome with regard to gender and race

#%% Visualizing the differences in outcome with regard to gender and race

import matplotlib
import matplotlib.pyplot as plt
from importlib import reload
# reload(matplotlib)
import seaborn as sns
from matplotlib.pyplot import title


# Only gender

sns.countplot(x = 'BMI_cat', hue = 'RIAGENDR', data = df_final)
plt.title('Ditribution of BMI categories across genders')
plt.xlabel('BMI categories')
plt.ylabel('Population')
plt.legend(title = 'Gender', labels = ['Male','Female'], frameon = False)
plt.grid(True, axis= 'y', alpha = 0.4, linestyle = '--')
plt.show()

# Only race

sns.countplot(x = 'BMI_cat', hue = 'RIDRETH3', data = df_final)
plt.title('Ditribution of BMI categories across races')
plt.xlabel('BMI categories')
plt.ylabel('Population')
plt.legend(title = 'Race', labels = ['Mexican American', 'Other Hispanic', 'Non-Hispanic White',
                                     'Non-Hispanic Black', 'Non-Hispanic Asian', 'Other Races'], frameon = False, prop = {'size':6})
plt.grid(True, axis= 'y', alpha = 0.4, linestyle = '--')
plt.show()


# Gender and race

#% Method 1

g = sns.FacetGrid(df_final, col ='RIDRETH3', height = 4, aspect = 1)
g.map(sns.countplot, 'BMI_cat' , hue = df_final['RIAGENDR'])
plt.ylabel('Population')
plt.grid(True, axis= 'y', alpha = 0.4, linestyle = '--')
plt.show()

#% Method 2


pivot_df = df_final.groupby(['BMI_cat','RIAGENDR','RIDRETH3']).size().unstack()
pivot_df.plot(kind = 'bar', stacked = True, figsize =(10,6))
plt.title('Ditribution of BMI categories across genders and race groups')
plt.legend(title = 'Race', labels = ['Mexican American', 'Other Hispanic', 'Non-Hispanic White',
                                     'Non-Hispanic Black', 'Non-Hispanic Asian', 'Other Races'], frameon = False, prop = {'size':6})
plt.grid(True, axis= 'y', alpha = 0.4, linestyle = '--')
plt.xlabel('BMI Categories and Gender Combinations')
plt.ylabel('Population')

"""# Descriptive Statistics"""

import statistics


## Outcome variable (BMI)


# BMI_mean_df = np.mean(df_final['BMXBMI'])
# print(BMI_mean_df)

# BMI_SD_df = np.std(df_final['BMXBMI'])
# print(BMI_SD_df)

# normal_df = (df_final['BMXBMI'] < 25).sum()
# print(normal_df)
# overweight_df = (df_final['BMXBMI'] >= 25).sum()
# print(overweight_df)




## Weighted descriptives

# total_individuals_weighted = df_final['WTDR2DPP'].sum()
# print(total_individuals_weighted)
# df_final['BMI_weighted_mean'] = (df_final['BMXBMI'] * df_final['WTDR2DPP']).sum() / total_individuals_weighted

# class_proportions_before = df_final['BMI_cat'].value_counts(normalize=True)

# df_final['BMI_weighted_count'] = df_final['WTDR2DPP'] * 1  # 1 represents each individual


# BMI_class_counts_after = df_final.groupby('BMI_cat')['BMI_weighted_count'].sum()
# total_individuals_after = df_final['BMI_weighted_count'].sum()
# class_proportions_after = BMI_class_counts_after / total_individuals_after

# print("Class proportions before weighting:")
# print(class_proportions_before)
# print("\nClass proportions after weighting:")
# print(class_proportions_after)



## Demographics
# males_df = (df_final['RIAGENDR'] == 1).sum()
# print(males_df)
# females_df = (df_final['RIAGENDR'] == 2).sum()
# print(females_df)

# age_mean_df = np.mean(df_final['RIDAGEYR'])
# print(age_mean_df)

# age_SD_df = np.std(df_final['RIDAGEYR'])
# print(age_SD_df)

## Races

# mex_am_df = (df_final['RIDRETH3'] == 1).sum()
# print(mex_am_df)
# other_his_df = (df_final['RIDRETH3'] == 2).sum()
# print(other_his_df)
# white_df = (df_final['RIDRETH3'] == 3).sum()
# print(white_df)
# black_df = (df_final['RIDRETH3'] == 4).sum()
# print(black_df)
# asian_df = (df_final['RIDRETH3'] == 6).sum()
# print(asian_df)
# other_races_df = (df_final['RIDRETH3'] == 7).sum()
# print(other_races_df)

"""# Splitting into train and test"""

# @title Stratiffied splitting (based on gender)

#%% Stratiffied splitting (based on gender)

from sklearn.model_selection import train_test_split

strat_train_set, strat_test_set = train_test_split(
    df_final, test_size = 0.2, stratify = df_final['RIAGENDR'], random_state=42)


# To verify the function of the splitter (How similar the proportions are regarding to the variables based on which the dataframe was stratified)
print(strat_test_set['RIAGENDR'].value_counts()/len(strat_test_set))
print(df_final['RIAGENDR'].value_counts()/len(df_final))

# @title Creating a copy of the train set

#%% Creating a copy of the train set

df_obesity = strat_train_set.copy()
df_obesity
# print(df_obesity.columns)

"""# Further explorarion of dataset through correlation"""

# @title Correlation between numerical values

# %%capture

#%% Correlation between numerical values

from pandas.plotting import scatter_matrix

some_num_attributes = ['BMXBMI','RIDAGEYR', 'INDFMPIR', 'Calorie_intake_mean', 'Protein_intake_mean', 'Carb_intake_mean',
       'Cholesterol_intake_mean', 'INDFMMPI', 'PAD680', 'SLD012', 'SLD013','HEI-2020']

scatter_matrix(df_obesity[some_num_attributes], figsize = (40,30))
plt.show()

# @title Seperating the outcome and the weights from other attributes

df_obesity = strat_train_set.drop(['BMXBMI','BMI_cat','WTDRD1PP','WTDR2DPP'], axis = 1)
df_obesity_labels_1 = (strat_train_set[['BMXBMI']].copy()).values.ravel() # Converting it to 1d array at the same time
df_obesity_labels_2 = (strat_train_set[['BMI_cat']].copy()).values.ravel()
weights_1_day = (strat_train_set[['WTDRD1PP']].copy()).values.ravel()
weights_2_day = (strat_train_set[['WTDR2DPP']].copy()).values.ravel()
# df_obesity_labels = strat_train_set['BMI_cat'].copy()

# df_obesity = strat_train_set.drop('BMI_cat', axis = 1)
# df_obesity_labels = strat_train_set['BMI_cat'].copy()

df_obesity_labels_1
# df_obesity_labels_2
# df_obesity

# @title Exploration and conversion of datatypes


# data_type = pd.DataFrame(df_obesity.dtypes)
# data_type

# print(df_obesity.columns)
df_obesity['RIAGENDR'] = df_obesity['RIAGENDR'].astype('category')
df_obesity['RIDRETH3'] = df_obesity['RIDRETH3'].astype('category')
df_obesity['DMDBORN4'] = df_obesity['DMDBORN4'].astype('category') # Dummy
df_obesity['DMDEDUC2'] = df_obesity['DMDEDUC2'].astype('category')
df_obesity['DMDMARTZ'] = df_obesity['DMDMARTZ'].astype('category')
df_obesity['CBQ506'] = df_obesity['CBQ506'].astype('category') # Dummy
df_obesity['CBQ536'] = df_obesity['CBQ536'].astype('category') # Dummy
df_obesity['CBQ551'] = df_obesity['CBQ551'].astype('category') # Dummy
df_obesity['CBQ830'] = df_obesity['CBQ830'].astype('category') # Dummy
df_obesity['CBQ845'] = df_obesity['CBQ845'].astype('category') # Dummy
df_obesity['CBQ860'] = df_obesity['CBQ860'].astype('category') # Dummy
df_obesity['CBQ875'] = df_obesity['CBQ875'].astype('category') # Dummy
df_obesity['CBQ890'] = df_obesity['CBQ890'].astype('category') # Dummy
df_obesity['CBQ645'] = df_obesity['CBQ645'].astype('category')
df_obesity['CBQ700'] = df_obesity['CBQ700'].astype('category')
df_obesity['DBQ780'] = df_obesity['DBQ780'].astype('category')
df_obesity['DBQ750'] = df_obesity['DBQ750'].astype('category')
df_obesity['DBQ760'] = df_obesity['DBQ760'].astype('category')
df_obesity['DBQ770'] = df_obesity['DBQ770'].astype('category')
df_obesity['CBQ905'] = df_obesity['CBQ905'].astype('category')
df_obesity['CBQ910'] = df_obesity['CBQ910'].astype('category')
df_obesity['CBQ685'] = df_obesity['CBQ685'].astype('category')
df_obesity['CBQ915'] = df_obesity['CBQ915'].astype('category')
df_obesity['CBD925'] = df_obesity['CBD925'].astype('category')
df_obesity['CBQ930'] = df_obesity['CBQ930'].astype('category')
df_obesity['CBQ935'] = df_obesity['CBQ935'].astype('category')
df_obesity['CBQ945'] = df_obesity['CBQ945'].astype('category')
df_obesity['CBQ950'] = df_obesity['CBQ950'].astype('category')
df_obesity['DBQ700'] = df_obesity['DBQ700'].astype('category')
df_obesity['CBQ596'] = df_obesity['CBQ596'].astype('category') # Dummy
df_obesity['DRQSDIET'] = df_obesity['DRQSDIET'].astype('category') # Dummy
df_obesity['DR2STY'] = df_obesity['DR2STY'].astype('category') # Dummy
df_obesity['FSDHH'] = df_obesity['FSDHH'].astype('category')
df_obesity['FSDAD'] = df_obesity['FSDAD'].astype('category')
df_obesity['INDFMMPC'] = df_obesity['INDFMMPC'].astype('category')
df_obesity['MCQ300C'] = df_obesity['MCQ300C'].astype('category') # Dummy
df_obesity['MCQ300A'] = df_obesity['MCQ300A'].astype('category') # Dummy
# df_obesity['MCQ371A'] = df_obesity['MCQ371A'].astype('category') # Dummy
# df_obesity['MCQ371B'] = df_obesity['MCQ371B'].astype('category') # Dummy
# df_obesity['MCQ371C'] = df_obesity['MCQ371C'].astype('category') # Dummy
# df_obesity['MCQ371D'] = df_obesity['MCQ371D'].astype('category') # Dummy
df_obesity['PAQ605'] = df_obesity['PAQ605'].astype('category') # Dummy
df_obesity['PAQ620'] = df_obesity['PAQ620'].astype('category') # Dummy
df_obesity['PAQ635'] = df_obesity['PAQ635'].astype('category') # Dummy
df_obesity['PAQ650'] = df_obesity['PAQ650'].astype('category') # Dummy
df_obesity['PAQ665'] = df_obesity['PAQ665'].astype('category') # Dummy
df_obesity['PAQ665'] = df_obesity['PAQ665'].astype('category') # Dummy
df_obesity['SLQ030'] = df_obesity['SLQ030'].astype('category')
df_obesity['SLQ040'] = df_obesity['SLQ040'].astype('category')
df_obesity['SLQ050'] = df_obesity['SLQ050'].astype('category') # Dummy
df_obesity['SLQ120'] = df_obesity['SLQ120'].astype('category')
# df_obesity['WHQ030'] = df_obesity['WHQ030'].astype('category')
# df_obesity['WHQ040'] = df_obesity['WHQ040'].astype('category')
# df_obesity['WHQ070'] = df_obesity['WHQ070'].astype('category') # Dummy
# df_obesity['WHQ225'] = df_obesity['WHQ225'].astype('category') # Ordinal



df_obesity
# df_obesity.select_dtypes(include = ['category'])
df_obesity.select_dtypes(include = [np.number])

#%% Testing
# df_obesity['FSDHH'].dtype
# df_obesity['DR2STY'].dtype

"""# Preparing the dataset for machine learning (Stage 2)"""

# @title Imputation of missing values

df_obesity_cat = df_obesity.select_dtypes(include = ['category'])
df_obesity_num = df_obesity.select_dtypes(include = [np.number])

from sklearn.impute import SimpleImputer

imputer_cat = SimpleImputer(strategy= 'most_frequent')
imputer_num = SimpleImputer(strategy= 'median')


print(imputer_cat.fit(df_obesity_cat))
print(imputer_num.fit(df_obesity_num))

#%% Testing

print(imputer_cat.statistics_)
print(df_obesity_cat.mode().values)

print(imputer_num.statistics_)
print(df_obesity_num.median().values)

# @title One-hot encoding of categorical variables

#**Should be reconsidered if the final model is underfit!**

from sklearn.preprocessing import OneHotEncoder

cat_encoder = OneHotEncoder(handle_unknown= 'ignore')
df_obesity_cat_1hot = cat_encoder.fit_transform(df_obesity_cat)

df_obesity_cat_1hot
# df_obesity_cat_1hot.toarray()

# @title Scaling and transformation of numerical data

# Trnasformation of input features

#1: Yeo-Johnson method (chosen over 'log' method, because data may contain zero values)

from sklearn.preprocessing import PowerTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler

transformer_num_feat = PowerTransformer(method = 'yeo-johnson')
obesity_num_trf = transformer_num_feat.fit_transform(df_obesity_num)
obesity_num_trf

scaler_num_feat = RobustScaler()
obesity_num_trf_scaled = scaler_num_feat.fit_transform(obesity_num_trf)

obesity_num_trf_scaled

# @title Visualizing the impact of transformation

import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# %%capture

# Histograms before and after transformation
for column in df_obesity_num.columns:
    sns.histplot(df_obesity_num[column], kde=True, label='Original')
    sns.histplot(obesity_num_trf_scaled[:, df_obesity_num.columns.tolist().index(column)], kde=True, label='Transformed and Scaled')
    plt.title(column)
    plt.legend()
    plt.show()

# Q-Q plots before and after transformation
for column in df_obesity_num.columns:
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    stats.probplot(df_obesity_num[column], dist="norm", plot=plt)
    plt.title('Original ' + column)

    plt.subplot(1, 2, 2)
    stats.probplot(obesity_num_trf_scaled[:, df_obesity_num.columns.tolist().index(column)], dist="norm", plot=plt)
    plt.title('Transformed and Scaled ' + column)

    plt.show()

# @title Visualization following scaling and transformation

# %%capture
# Input features

# new_columns = df_obesity_num.columns

# sample_transf_scaled_df = pd.DataFrame(obesity_num_trf_scaled, columns= new_columns, index= df_obesity_num.index)
# sample_transf_scaled_df

# from pandas.plotting import scatter_matrix

# some_num_attributes_input = ['RIDAGEYR', 'INDFMPIR', 'Calorie_intake_mean', 'Protein_intake_mean', 'Carb_intake_mean',
#        'Cholesterol_intake_mean', 'INDFMMPI', 'PAD680', 'SLD012', 'SLD013','HEI-2020']

# scatter_matrix(sample_transf_scaled_df[some_num_attributes_input], figsize = (40,30))
# plt.show()

"""# Transformation Pipelines"""

# @title Numerical variables

from sklearn.pipeline import Pipeline

num_pipeline = Pipeline([
   ('impute', SimpleImputer(strategy= 'median')),
   ('transform', PowerTransformer(method = 'yeo-johnson')),
   ('standardize', RobustScaler())
])
num_pipeline

# @title Applying 'num_pipeline' to numerical attributes

obesity_num_prepared = num_pipeline.fit_transform(df_obesity_num)
obesity_num_prepared


# Creating a dataframe
df_obesity_num_prepared = pd.DataFrame(
    obesity_num_prepared, columns = num_pipeline.get_feature_names_out(),
    index = df_obesity_cat.index)
# df_obesity_num_prepared

# @title Categorical variables

from sklearn.pipeline import Pipeline

cat_pipeline = Pipeline([
   ('impute', SimpleImputer(strategy= 'most_frequent')),
   ('encoder', OneHotEncoder(handle_unknown= 'ignore')),
])
cat_pipeline

# @title Applying 'cat_pipeline' to categorical attributes

from sklearn.compose import ColumnTransformer

obesity_cat_prepared = cat_pipeline.fit_transform(df_obesity_cat)
obesity_cat_prepared.shape


# # Getting the original column names
# original_feature_names = df_obesity_cat.columns

# encoded_feature_names = cat_pipeline.named_steps['encoder'].get_feature_names_out()

# new_feature_names = [original_feature_names[int(name.split('_')[0][1:])] + '_' + name.split('_')[1] for name in encoded_feature_names]


# # # Creating a dataframe
# df_obesity_cat_prepared = pd.DataFrame(
#     obesity_cat_prepared.toarray(), columns = new_feature_names,
#     index = df_obesity_num.index)
# df_obesity_cat_prepared.head(2)

# @title Making a uniform transformer

from sklearn.compose import make_column_selector, make_column_transformer

preprocessing = make_column_transformer(
    (num_pipeline, make_column_selector(dtype_include=np.number)),
    (cat_pipeline, make_column_selector(dtype_include='category'))
)


df_obesity_prepared = preprocessing.fit_transform(df_obesity)


# df_obesity_prepared.shape

# preprocessing.get_feature_names_out()

# @title Visualizing the preprocessing procedure

preprocessing

# @title Seperating behavioral data


# variables_CBQs = [col for col in df_obesity.columns if col.startswith('CBQ')]
# variables_DBQs = [col for col in df_obesity.columns if col.startswith('DBQ')]

# variables_CBQs
# variables_DBQs

# @title Factor Analysis of Mixed Data (There's a problem with the package!)
# To derive a uniform score

# import prince

# from prince import FAMD
# from prince import MFA

# behavioral_vars = [
#     'CBQ506', 'CBQ536', 'CBQ551', 'CBQ830', 'CBQ845',
#     'CBQ860', 'CBQ875', 'CBQ890', 'CBQ645', 'CBQ700',
#     'CBQ905', 'CBQ910', 'CBQ685', 'CBQ915', 'CBQ930',
#     'CBQ935', 'CBQ945', 'CBQ950', 'CBQ596'
# ]

# behavioral_vars_df = df_obesity[behavioral_vars]
# behavioral_vars_df_columns = behavioral_vars_df.columns

# ## With imputation only

# imputer_cat.fit(behavioral_vars_df)


# behavioral_vars_imputed = imputer_cat.transform(behavioral_vars_df)
# df_behavioral_vars_imputed = pd.DataFrame(behavioral_vars_imputed, columns= behavioral_vars_df_columns)


# BMI_cats_mfa = pd.DataFrame(df_obesity_labels_2)

# # combined_data = BMI_cats_mfa.join(behavioral_data)


# groups = {'numerical': BMI_cats_mfa.columns.tolist(), 'categorical': df_behavioral_vars_imputed.columns.tolist()}

# mfa = prince.MFA(
# groups=groups,
# n_components=2,
# n_iter=3,
# random_state=42
# )

# # mfa = mfa.fit(X)

# @title PCA

## PCA expects all variables as 'continuous'; seems not worthy to our analysis!

# from sklearn.decomposition import PCA
# # from sklearn.preprocessing import OneHotEncoder

# behavioral_vars = [
#     'CBQ506', 'CBQ536', 'CBQ551', 'CBQ830', 'CBQ845',
#     'CBQ860', 'CBQ875', 'CBQ890', 'CBQ645', 'CBQ700',
#     'CBQ905', 'CBQ910', 'CBQ685', 'CBQ915', 'CBQ930',
#     'CBQ935', 'CBQ945', 'CBQ950', 'CBQ596'
# ]

# behavioral_vars_df = df_obesity[behavioral_vars]
# behavioral_vars_df_columns = behavioral_vars_df.columns


# ## With imputation only

# imputer_cat.fit(behavioral_vars_df)


# behavioral_vars_imputed = imputer_cat.transform(behavioral_vars_df)
# df_behavioral_vars_imputed = pd.DataFrame(behavioral_vars_imputed, columns= behavioral_vars_df_columns)
# # df_behavioral_vars_imputed


# ## With complete preprocessing
# # behavioral_data_matrix = (cat_pipeline.fit_transform(df_obesity[behavioral_vars])).todense()
# # behavioral_data_df = pd.DataFrame(behavioral_data_matrix)

# # feature_names = cat_pipeline.named_steps['encoder'].get_feature_names_out(behavioral_vars)

# # behavioral_data_df.columns = feature_names

# # BMI_cats_pca = pd.DataFrame(df_obesity_labels_2)

# # combined_data_pca = pd.concat([behavioral_data_df, BMI_cats_pca], axis=1)





# pca = PCA(n_components=1, random_state=42)
# df_behavioral_vars_imputed['pca_score'] = pca.fit_transform(df_behavioral_vars_imputed)
# df_behavioral_vars_imputed
# # # print(pca.n_components_)

# behavior_components_df = pd.DataFrame(pca.components_, columns=df_behavioral_vars_imputed.columns)
# behavior_components_df

# sorted_behavior_components_df = behavior_components_df.abs().sort_values(by=0, axis=1, ascending=False)
# print(sorted_behavior_components_df)

# @title Multiple correspondence analysis (MCA)

## MCA is used when more than two categorical variables are investigated



# import prince
# from prince import MCA


# behavioral_vars = [
#     'CBQ506', 'CBQ536', 'CBQ551', 'CBQ830', 'CBQ845',
#     'CBQ860', 'CBQ875', 'CBQ890', 'CBQ645', 'CBQ700',
#     'CBQ905', 'CBQ910', 'CBQ685', 'CBQ915', 'CBQ930',
#     'CBQ935', 'CBQ945', 'CBQ950', 'CBQ596'
# ]

# behavioral_vars_df = df_obesity[behavioral_vars]
# behavioral_vars_df_columns = behavioral_vars_df.columns

# ## With imputation only

# imputer_cat.fit(behavioral_vars_df)


# behavioral_vars_imputed = imputer_cat.transform(behavioral_vars_df)
# df_behavioral_vars_imputed = pd.DataFrame(behavioral_vars_imputed, columns= behavioral_vars_df_columns)
# df_behavioral_vars_imputed

# MCA = MCA(n_components=1, random_state=42)
# MCA.fit(df_behavioral_vars_imputed)
# behavior_scores = MCA.transform(df_behavioral_vars_imputed)
# # behavior_scores
# print(MCA.explained_inertia_)

# final_behavior_scores = df_behavioral_vars_imputed.dot(behavior_scores.T)

# column_coordinates_mca = MCA.column_coordinates(df_behavioral_vars_imputed)
# column_coordinates_mca

# final_behavior_scores = np.dot(df_behavioral_vars_imputed.values, column_coordinates_mca.values)

"""# Training the models"""

# @title Decision tree classifier

sample_weights = weights_2_day
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import make_pipeline

tree_class = make_pipeline (preprocessing, DecisionTreeClassifier(random_state=42, max_depth = 11, max_features = 73, min_samples_split = 69))
tree_class.fit(df_obesity,df_obesity_labels_2, decisiontreeclassifier__sample_weight= sample_weights)

# @title Testing the decision tree classifier

obesity_prediction_tree_class = tree_class.predict(df_obesity)
print(obesity_prediction_tree_class[:5].round(0))
print((df_obesity_labels_2[:5]))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

tree_class_acc = accuracy_score(df_obesity_labels_2,obesity_prediction_tree_class,
                                    sample_weight=sample_weights)

tree_class_acc

# @title DT visualization

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt


full_pipeline_DT = Pipeline([
    ('preprocessing', preprocessing),
    ('tree_class', DecisionTreeClassifier(random_state=42, max_depth = 61, max_features = 24, min_samples_split = 81))
])

full_pipeline_DT.fit(df_obesity,df_obesity_labels_2)

features_names_DT = full_pipeline_DT.named_steps['preprocessing'].get_feature_names_out()

D_tree = full_pipeline_DT['tree_class']

fig, ax = plt.subplots(figsize=(30, 20))
plot_tree(D_tree, filled=True, feature_names=features_names_DT, class_names=True, ax=ax)
plt.savefig('tree_high_res.png', dpi=600)
plt.show()

from google.colab import files
files.download('tree_high_res.png')

# @title Random forest classifier

from sklearn.ensemble import RandomForestClassifier

# Hyperparameters where obtained by the randomized grid search below

forest_class = make_pipeline (preprocessing, RandomForestClassifier(random_state=42, max_depth=61, max_features=24, min_samples_split=81))
forest_class.fit(df_obesity,df_obesity_labels_2, randomforestclassifier__sample_weight= sample_weights)

# @title Testing Random forest classifier

obesity_predict_frst_class = forest_class.predict(df_obesity)
print(obesity_predict_frst_class[:5].round(0))
print((df_obesity_labels_2[:5]))

from sklearn.metrics import mean_squared_error

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

forest_class_acc = accuracy_score(df_obesity_labels_2, obesity_predict_frst_class,
                                      sample_weight=sample_weights)
forest_class_acc

# @title RF visualization (One sample tree)

from sklearn.tree import export_graphviz
from subprocess import call
from IPython.display import Image, display


feature_names = forest_class.named_steps['columntransformer'].get_feature_names_out()
tree_in_forest = forest_class.named_steps['randomforestclassifier'].estimators_[5]

# Export the tree as a .dot file
export_graphviz(tree_in_forest, out_file='tree.dot', feature_names=feature_names, filled=True)

from subprocess import call
call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])

from IPython.display import Image
Image(filename='tree.png')

# @title Support Vector Machine (classifier)

from sklearn.svm import SVC

SVC_class = make_pipeline (preprocessing, SVC(random_state= 42,  C=0.001, probability = True))
SVC_class.fit(df_obesity,df_obesity_labels_2, svc__sample_weight= sample_weights)

# @title Testing Support Vector Machine (classifier)


obesity_predict_svc_class = SVC_class.predict(df_obesity)
print(obesity_predict_frst_class[:5].round(0))
print((df_obesity_labels_2[:5]))


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

SVC_class_acc = accuracy_score(df_obesity_labels_2, obesity_predict_svc_class,
                                      sample_weight=sample_weights)
SVC_class_acc

# @title KNN (classifier)

from sklearn.neighbors import KNeighborsClassifier

KNN_class = make_pipeline (preprocessing, KNeighborsClassifier(weights = 'distance', n_neighbors = 29))
KNN_class.fit(df_obesity,df_obesity_labels_2)

# @title Testing KNN (classifier)

obesity_predict_knn_class = KNN_class.predict(df_obesity)
print(obesity_predict_knn_class[:5].round(0))
print((df_obesity_labels_2[:5]))



from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

KNN_class_acc = accuracy_score(df_obesity_labels_2, obesity_predict_knn_class,
                                      sample_weight=sample_weights)
KNN_class_acc

# @title Gradient Boosting classifier

# !pip install xgboost

sample_weights = weights_2_day

from xgboost import XGBClassifier
from sklearn.pipeline import make_pipeline




XGB_class = make_pipeline (preprocessing, XGBClassifier(random_state=42))
XGB_class.fit(df_obesity,df_obesity_labels_2, xgbclassifier__sample_weight= sample_weights)

# @title Testing Gradient Boosting

obesity_predict_xgb_class = XGB_class.predict(df_obesity)
print(obesity_predict_xgb_class[:5].round(0))
print((df_obesity_labels_2[:5]))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

xgb_class_acc = accuracy_score(df_obesity_labels_2, obesity_predict_xgb_class,
                                      sample_weight=sample_weights)
xgb_class_acc

# @title XGBoost visualization


from xgboost import plot_tree
import matplotlib.pyplot as plt

# Get the feature names from the ColumnTransformer
column_transformer = XGB_class.named_steps['columntransformer']
feature_names = []

# Loop through transformers to get feature names
for _, trans, columns in column_transformer.transformers_:
    if hasattr(trans, 'get_feature_names_out'):
        names = trans.get_feature_names_out(columns)
    else:
        names = columns
    feature_names.extend(names)

# Extract the first tree from the XGBClassifier
tree_index = 0  # You can change this index to visualize a different tree
fig, ax = plt.subplots(figsize=(150, 100), dpi=200)  # Bigger size and higher resolution
plot_tree(XGB_class.named_steps['xgbclassifier'], num_trees=tree_index, ax=ax, feature_names=feature_names)
plt.show()

"""# Cross-validation of the models"""

# @title Cross-validation of DT classifier


from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Define the metrics you want to calculate
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Perform cross-validation with multiple metrics
tree_class_scores = cross_validate(tree_class, df_obesity, df_obesity_labels_2,
                                   scoring=scoring, cv=10,
                                   fit_params={'decisiontreeclassifier__sample_weight': sample_weights})



# Extract the scores for each metric
accuracy_scores_DT = tree_class_scores['test_accuracy']
print(pd.Series(accuracy_scores_DT).describe())
precision_scores_DT = tree_class_scores['test_precision']
print(pd.Series(precision_scores_DT).describe())
recall_scores_DT = tree_class_scores['test_recall']
print(pd.Series(recall_scores_DT).describe())
f1_scores_DT = tree_class_scores['test_f1']
print(pd.Series(f1_scores_DT).describe())
roc_auc_scores_DT = tree_class_scores['test_roc_auc']
print(pd.Series(roc_auc_scores_DT).describe())

# @title Cross-validation of RF classifier

# from sklearn.model_selection import cross_val_score

# forest_class_acc_scores = cross_val_score(forest_class, df_obesity,df_obesity_labels_2,
#                                          scoring = 'accuracy', cv =10,
#                                            fit_params={'randomforestclassifier__sample_weight': sample_weights})

# pd.Series(forest_class_acc_scores).describe()

from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Define the metrics you want to calculate
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Perform cross-validation with multiple metrics
forest_class_scores = cross_validate(forest_class, df_obesity, df_obesity_labels_2,
                                   scoring=scoring, cv=10,
                                   fit_params={'randomforestclassifier__sample_weight': sample_weights})

# Extract the scores for each metric
accuracy_scores_RF = forest_class_scores['test_accuracy']
print(pd.Series(accuracy_scores_RF).describe())
precision_scores_RF = forest_class_scores['test_precision']
print(pd.Series(precision_scores_RF).describe())
recall_scores_RF = forest_class_scores['test_recall']
print(pd.Series(recall_scores_RF).describe())
f1_scores_RF = forest_class_scores['test_f1']
print(pd.Series(f1_scores_RF).describe())
roc_auc_scores_RF = forest_class_scores['test_roc_auc']
print(pd.Series(roc_auc_scores_RF).describe())

# @title Cross-validation of SVC classifier


# from sklearn.model_selection import cross_val_score

# SVC_class_acc_score = cross_val_score(SVC_class, df_obesity,df_obesity_labels_2,
#                                         scoring = 'accuracy', cv =10,
#                                         fit_params={'svc__sample_weight': sample_weights})

# pd.Series(SVC_class_acc_score).describe()

from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Define the metrics you want to calculate
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Perform cross-validation with multiple metrics
SVC_class_scores = cross_validate(SVC_class, df_obesity, df_obesity_labels_2,
                                   scoring=scoring, cv=10,
                                   fit_params={'svc__sample_weight': sample_weights})

# Extract the scores for each metric
accuracy_scores_SVC = SVC_class_scores['test_accuracy']
print(pd.Series(accuracy_scores_SVC).describe())
precision_scores_SVC = SVC_class_scores['test_precision']
print(pd.Series(precision_scores_SVC).describe())
recall_scores_SVC = SVC_class_scores['test_recall']
print(pd.Series(recall_scores_SVC).describe())
f1_scores_SVC = SVC_class_scores['test_f1']
print(pd.Series(f1_scores_SVC).describe())
roc_auc_scores_SVC = SVC_class_scores['test_roc_auc']
print(pd.Series(roc_auc_scores_SVC).describe())

# @title Cross-validation of KNN classifier


# from sklearn.model_selection import cross_val_score

# KNN_class_acc_score = cross_val_score(KNN_class, df_obesity,df_obesity_labels_2,
#                                         scoring = 'accuracy', cv =10,
#                                         )


# pd.Series(KNN_class_acc_score).describe()

from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Define the metrics you want to calculate
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Perform cross-validation with multiple metrics
KNN_class_scores = cross_validate(KNN_class, df_obesity, df_obesity_labels_2,
                                   scoring=scoring, cv=10,
                                   )

# Extract the scores for each metric
accuracy_scores_KNN = KNN_class_scores['test_accuracy']
print(pd.Series(accuracy_scores_KNN).describe())
precision_scores_KNN = KNN_class_scores['test_precision']
print(pd.Series(precision_scores_KNN).describe())
recall_scores_KNN = KNN_class_scores['test_recall']
print(pd.Series(recall_scores_KNN).describe())
f1_scores_KNN = KNN_class_scores['test_f1']
print(pd.Series(f1_scores_KNN).describe())
roc_auc_scores_KNN = KNN_class_scores['test_roc_auc']
print(pd.Series(roc_auc_scores_KNN).describe())

# @title Cross validation of XGBoost Classifier



# from sklearn.model_selection import cross_val_score

# XGB_class_acc_score = cross_val_score(XGB_class, df_obesity,df_obesity_labels_2,
#                                         scoring = 'accuracy', cv =10,
#                                         fit_params={'xgbclassifier__sample_weight': sample_weights})

# pd.Series(XGB_class_acc_score).describe()

from sklearn.model_selection import cross_validate
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Define the metrics you want to calculate
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Perform cross-validation with multiple metrics
XGB_class_scores = cross_validate(XGB_class, df_obesity, df_obesity_labels_2,
                                   scoring=scoring, cv=10,
                                   fit_params={'xgbclassifier__sample_weight': sample_weights})

# Extract the scores for each metric
accuracy_scores_XGB = XGB_class_scores['test_accuracy']
print(pd.Series(accuracy_scores_XGB).describe())
precision_scores_XGB = XGB_class_scores['test_precision']
print(pd.Series(precision_scores_XGB).describe())
recall_scores_XGB = XGB_class_scores['test_recall']
print(pd.Series(recall_scores_XGB).describe())
f1_scores_XGB = XGB_class_scores['test_f1']
print(pd.Series(f1_scores_XGB).describe())
roc_auc_scores_XGB = XGB_class_scores['test_roc_auc']
print(pd.Series(roc_auc_scores_XGB).describe())

# @title Comparative visualization model performances (Cross-validation)


import numpy as np
import matplotlib.pyplot as plt

# Define the metrics and their corresponding scores for each model
metrics_CV = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC']
model_names_CV = ['DT classifier', 'RF classifier', 'SVC classifier', 'XGB classifier', 'KNN classifier']

accuracy_scores_CV = [0.692, 0.745, 0.742, 0.743, 0.742]
precision_scores_CV = [0.780, 0.747, 0.798, 0.783, 0.748]
recall_scores_CV = [0.811, 0.989, 0.871, 0.902, 0.981]
f1_scores_CV = [0.795, 0.851, 0.833, 0.888, 0.849]
roc_scores_CV = [0.640, 0.725, 0.707, 0.710, 0.676]

# Combine the scores of all metrics for each model into a single list of lists
all_scores_CV = np.array([accuracy_scores_CV, precision_scores_CV, recall_scores_CV, f1_scores_CV, roc_scores_CV])

# Compute angles for each axis
angles_CV = np.linspace(0, 2 * np.pi, len(metrics_CV), endpoint=False).tolist()
angles_CV += angles_CV[:1]  # Close the plot

fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))

# Draw one axe per variable and add labels
plt.xticks(angles_CV[:-1], metrics_CV, color='grey', size=10)

# Draw ylabels
ax.set_rlabel_position(0)
plt.yticks([0.25, 0.5, 0.75], ["0.25", "0.50", "0.75"], color="grey", size=7)
plt.ylim(0, 1)

# Plot data
for i in range(len(model_names_CV)):
    values = all_scores_CV[:, i].tolist()
    ax.plot(angles_CV, values + [values[0]], linewidth=1, linestyle='solid', label=model_names_CV[i])  # Connect back to the start point

# Fill area
ax.fill(angles_CV, values + [values[0]], 'b', alpha=0.1)

plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
plt.show()

"""# Grid Search"""

# @title Decision Tree Classifier (Hyperparameter Tuning) (Multiple parameters)

# from sklearn.model_selection import RandomizedSearchCV
# from scipy.stats import randint
# from sklearn.pipeline import Pipeline
# from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score
# from sklearn.tree import DecisionTreeClassifier



# # Create a pipeline
# full_pipeline_DT = Pipeline([
#     ('preprocessing', preprocessing),
#     ('tree_class', DecisionTreeClassifier(random_state=42))
# ])

# # Update the parameter distribution dictionary with multiple parameters
# param_distrbs = {
#     'tree_class__max_features': randint(low=10, high=100),
#     'tree_class__max_depth': randint(low=10, high=100),
#     'tree_class__min_samples_split': randint(low=10, high=100),
# }

# # Define multiple scoring metrics
# scoring = {
#     'accuracy': 'accuracy',
#     'precision': 'precision_macro',
#     'roc_auc': 'roc_auc_ovr',
#     'f1': 'f1_macro'
# }

# # Create RandomizedSearchCV with multiple scoring
# rnd_search_DT = RandomizedSearchCV(
#     full_pipeline_DT, param_distributions=param_distrbs, n_iter=10, cv=10,
#     scoring=scoring, refit='roc_auc', random_state=42, n_jobs=-1
# )

# # Fit the RandomizedSearchCV
# rnd_search_DT.fit(df_obesity, df_obesity_labels_2)

# # Get the best parameters for each scoring metric
# best_params_DT = rnd_search_DT.best_params_
# print("Best Parameters:")
# print(best_params_DT)

# # Get the best scores for each scoring metric
# best_scores_DT = rnd_search_DT.best_score_
# print("Best Scores:")
# print(best_scores_DT)

# @title Random Forest Classifier (Hyperparameter Tuning)

# from sklearn.model_selection import RandomizedSearchCV
# from scipy.stats import randint

# full_pipeline = Pipeline([
#     ('preprocessing',preprocessing),
#     ('forest_calss',RandomForestClassifier(random_state=42))
# ])

# param_distrbs = {'RandomForestClassifier__max_features':randint(low=10,high=100)}
# rnd_search = RandomizedSearchCV(
#     full_pipeline, param_distributions=param_distrbs, n_iter = 10, cv = 3,
#     scoring='neg_root_mean_squared_error', random_state=42
# )
# rnd_search.fit(df_obesity,df_obesity_labels_2)
# rnd_search.best_params_

# @title Random Forest Classifier (Hyperparameter Tuning) (Multiple parameters)

# from sklearn.model_selection import RandomizedSearchCV
# from scipy.stats import randint
# from sklearn.pipeline import Pipeline
# from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score
# from sklearn.ensemble import RandomForestClassifier


# # Create a pipeline
# full_pipeline = Pipeline([
#     ('preprocessing', preprocessing),
#     ('forest_class', RandomForestClassifier(random_state=42))
# ])

# # Update the parameter distribution dictionary with multiple parameters
# param_distrbs = {
#     'forest_class__max_features': randint(low=10, high=100),
#     'forest_class__max_depth': randint(low=10, high=100),
#     'forest_class__min_samples_split': randint(low=10, high=100),
# }

# # Define multiple scoring metrics
# scoring = {
#     'accuracy': 'accuracy',
#     'precision': 'precision_macro',
#     'roc_auc': 'roc_auc_ovr',
#     'f1': 'f1_macro'
# }

# # Create RandomizedSearchCV with multiple scoring
# rnd_search = RandomizedSearchCV(
#     full_pipeline, param_distributions=param_distrbs, n_iter=10, cv=10,
#     scoring=scoring, refit='roc_auc', random_state=42, n_jobs=-1
# )

# # Fit the RandomizedSearchCV
# rnd_search.fit(df_obesity, df_obesity_labels_2)

# # Get the best parameters for each scoring metric
# best_params = rnd_search.best_params_
# print("Best Parameters:")
# print(best_params)

# # Get the best scores for each scoring metric
# best_scores = rnd_search.best_score_
# print("Best Scores:")
# print(best_scores)

# @title SVC Classifier (Hyperparameter Tuning)

# from sklearn.model_selection import RandomizedSearchCV
# from sklearn.svm import SVC
# import numpy as np


# # Create a pipeline
# full_pipeline_svc = Pipeline([
#     ('preprocessing', preprocessing),
#     ('SVC_class', SVC(random_state=42))
# ])

# # Define the parameter values that should be searched
# param_dist = {'SVC_class__C': np.logspace(-3, 2, 6)}
#               # 'SVC_class__gamma': np.logspace(-3, 2, 6),
#               # 'SVC_class__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}


# scoring = {
#     'accuracy': 'accuracy',
#     'precision': 'precision_macro',
#     'roc_auc': 'roc_auc_ovr',
#     'f1': 'f1_macro'
# }

# random_search_svc = RandomizedSearchCV(full_pipeline_svc, param_distributions=param_dist, n_iter=100, cv=5,
#                                    scoring = scoring, refit = 'roc_auc', verbose=2, random_state=42, n_jobs=-1)

# # Fit the model
# random_search_svc.fit(df_obesity, df_obesity_labels_2)

# # # Get the best parameters for each scoring metric
# best_params_svc = random_search_svc.best_params_
# print("Best Parameters:")
# print(best_params_svc)

# # Get the best scores for each scoring metric
# best_scores_svc = random_search_svc.best_score_
# print("Best Scores:")
# print(best_scores_svc)

# @title XGB Classifier (Hyperparameter Tuning)


# from sklearn.model_selection import RandomizedSearchCV
# from scipy.stats import randint
# from scipy.stats import uniform
# from sklearn.pipeline import Pipeline
# from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score



# # # Create a pipeline
# full_pipeline_xgb = Pipeline([
#     ('preprocessing', preprocessing),
#     ('XGB_class', XGBClassifier(random_state=42))
# ])

# param_distrbs = {
#     'XGB_class__n_estimators': randint(low=10, high=100),
#     'XGB_class__max_depth': randint(low=10, high=100),
#     'XGB_class__min_child_weight': randint(low=1, high=100),
#     'XGB_class__gamma': randint(low=0, high=100),
#     'XGB_class__subsample': uniform(loc=0.1, scale=0.9),
#     'XGB_class__colsample_bytree': uniform(loc=0.1, scale=0.9),
#     'XGB_class__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
# }


# scoring = {
#     'accuracy': 'accuracy',
#     'precision': 'precision_macro',
#     'roc_auc': 'roc_auc_ovr',
#     'f1': 'f1_macro'
# }


# rnd_search_xgb = RandomizedSearchCV(
#     full_pipeline_xgb, param_distributions=param_distrbs, n_iter=10, cv=10,
#     scoring=scoring, refit='roc_auc', random_state=42, n_jobs=-1
# )

# rnd_search_xgb.fit(df_obesity, df_obesity_labels_2)

# best_params_xgb = rnd_search_xgb.best_params_
# print("Best Parameters of XGBooster:")
# print(best_params_xgb)


# best_scores_xgb = rnd_search_xgb.best_score_
# print("Best Scores of XGBooster:")
# print(best_scores_xgb)

# @title KNN Classifier (Hyperparameter Tuning) (Multiple parameters)

# from sklearn.model_selection import RandomizedSearchCV
# from scipy.stats import randint
# from sklearn.pipeline import Pipeline
# from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, f1_score




# # Create a pipeline
# full_pipeline_KNN = Pipeline([
#     ('preprocessing', preprocessing),
#     ('KNN_class', KNeighborsClassifier())
# ])

# # Update the parameter distribution dictionary with multiple parameters
# k_range = list(range(1, 31))
# weight_options = ['uniform', 'distance']

# params_KNN = dict(KNN_class__n_neighbors=k_range, KNN_class__weights=weight_options)

# # Define multiple scoring metrics
# scoring = {
#     'accuracy': 'accuracy',
#     'precision': 'precision_macro',
#     'roc_auc': 'roc_auc_ovr',
#     'f1': 'f1_macro'
# }

# # Create RandomizedSearchCV with multiple scoring
# rnd_search_KNN = RandomizedSearchCV(
#     full_pipeline_KNN, param_distributions=params_KNN, n_iter=10, cv=10,
#     scoring=scoring, refit='roc_auc', random_state=42, n_jobs=-1
# )

# # Fit the RandomizedSearchCV
# rnd_search_KNN.fit(df_obesity, df_obesity_labels_2)

# # Get the best parameters for each scoring metric
# best_params_KNN = rnd_search_KNN.best_params_
# print("Best Parameters:")
# print(best_params_KNN)

# # Get the best scores for each scoring metric
# best_scores_KNN = rnd_search_KNN.best_score_
# print("Best Scores:")
# print(best_scores_KNN)

"""# Testing on the test set"""

# @title DT classifier

X_test_1 = strat_test_set.drop('BMXBMI',axis=1)
X_test = X_test_1.drop('BMI_cat',axis=1)

y_test_1 = strat_test_set['BMXBMI'].copy()
y_test_2 = strat_test_set['BMI_cat'].copy()

# # print(np.unique(y_test_2))

predictions_DT_class = tree_class.predict(X_test)
final_acc_DT_class = accuracy_score(y_test_2, predictions_DT_class)
print(final_acc_DT_class)

# @title RF classifier

X_test_1 = strat_test_set.drop('BMXBMI',axis=1)
X_test = X_test_1.drop('BMI_cat',axis=1)

y_test_1 = strat_test_set['BMXBMI'].copy()
y_test_2 = strat_test_set['BMI_cat'].copy()

predictions_RF_class = forest_class.predict(X_test)
final_acc_RF_class = accuracy_score(y_test_2, predictions_RF_class)
print(final_acc_RF_class)

# @title SVC classifier

predictions_SVC_class = SVC_class.predict(X_test)
final_acc_SVC_class = accuracy_score(y_test_2, predictions_SVC_class)
print(final_acc_SVC_class)

# @title XGBooster

X_test_1 = strat_test_set.drop('BMXBMI',axis=1)
X_test = X_test_1.drop('BMI_cat',axis=1)

y_test_1 = strat_test_set['BMXBMI'].copy()
y_test_2 = strat_test_set['BMI_cat'].copy()

predictions_XGB_class = XGB_class.predict(X_test)
final_acc_XGB_class =accuracy_score(y_test_2, predictions_XGB_class)
print(final_acc_XGB_class)

# @title KNN classifier

X_test_1 = strat_test_set.drop('BMXBMI',axis=1)
X_test = X_test_1.drop('BMI_cat',axis=1)

y_test_1 = strat_test_set['BMXBMI'].copy()
y_test_2 = strat_test_set['BMI_cat'].copy()

predictions_KNN_class = KNN_class.predict(X_test)
final_acc_KNN_class =accuracy_score(y_test_2, predictions_KNN_class)
print(final_acc_KNN_class)

"""# Assessing the performance of the selected models"""

# @title DT classifier (Complete performance metrics)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix



accuracy_DT_class = accuracy_score(y_test_2, predictions_DT_class)
print(accuracy_DT_class)

precision_DT_class = precision_score(y_test_2, predictions_DT_class)
print(precision_DT_class)

recall_DT_class = recall_score(y_test_2, predictions_DT_class)
print(recall_DT_class)

F1_DT_class = f1_score(y_test_2, predictions_DT_class)
print(F1_DT_class)

roc_auc_DT_class = roc_auc_score(y_test_2, tree_class.predict_proba(X_test)[:, 1])
print(roc_auc_DT_class)


## Visualization of ROC
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt


probs = tree_class.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = roc_curve(y_test_2, preds)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# @title DT classifier (Confusion matrix)


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


predictions_DT_class = tree_class.predict(X_test)

cm = confusion_matrix(y_test_2, predictions_DT_class)

cm_df = pd.DataFrame(cm, index=[i for i in ["Actual - No", "Actual - Yes"]],
                     columns=[i for i in ["Predicted - No", "Predicted - Yes"]])

plt.figure(figsize=(7,5))

sns.heatmap(cm_df, annot=True, fmt="d", cmap="YlGnBu")

plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

# @title RF classifier (Complete performance metrics)

accuracy_RF_class = accuracy_score(y_test_2, predictions_RF_class)
print(accuracy_RF_class)

precision_RF_class = precision_score(y_test_2, predictions_RF_class)
print(precision_RF_class)

recall_RF_class = recall_score(y_test_2, predictions_RF_class)
print(recall_RF_class)

F1_RF_class = f1_score(y_test_2, predictions_RF_class)
print(F1_RF_class)

roc_auc_RF_class = roc_auc_score(y_test_2, forest_class.predict_proba(X_test)[:, 1])
print(roc_auc_RF_class)


## Visualization of ROC
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt


probs = forest_class.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = roc_curve(y_test_2, preds)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# @title RF classifier (Confusion matrix)


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


predictions_RF_class = forest_class.predict(X_test)

cm_RF = confusion_matrix(y_test_2, predictions_RF_class)

cm_RF_df = pd.DataFrame(cm_RF, index=[i for i in ["Actual - No", "Actual - Yes"]],
                     columns=[i for i in ["Predicted - No", "Predicted - Yes"]])

plt.figure(figsize=(7,5))

sns.heatmap(cm_RF_df, annot=True, fmt="d", cmap="YlGnBu")

plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

# @title SVC classifier (Complete performance metrics)


accuracy_SVC_class = accuracy_score(y_test_2, predictions_SVC_class)
print(accuracy_SVC_class)

precision_SVC_class = precision_score(y_test_2, predictions_SVC_class)
print(precision_SVC_class)

recall_SVC_class = recall_score(y_test_2, predictions_SVC_class)
print(recall_SVC_class)

F1_SVC_class = f1_score(y_test_2, predictions_SVC_class)
print(F1_SVC_class)

roc_auc_SVC_class = roc_auc_score(y_test_2, SVC_class.predict_proba(X_test)[:, 1])
print(roc_auc_SVC_class)

## Visualization of ROC
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt


probs = SVC_class.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = roc_curve(y_test_2, preds)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel

# @title SVC classifier (Confusion matrix)


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


predictions_SVC_class = SVC_class.predict(X_test)

cm_SVC = confusion_matrix(y_test_2, predictions_SVC_class)

cm_SVC_df = pd.DataFrame(cm_SVC, index=[i for i in ["Actual - No", "Actual - Yes"]],
                     columns=[i for i in ["Predicted - No", "Predicted - Yes"]])

plt.figure(figsize=(7,5))

sns.heatmap(cm_SVC_df, annot=True, fmt="d", cmap="YlGnBu")

plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

# @title XGBoost Classifier (Complete performance metrics)

from sklearn.preprocessing import label_binarize
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix


accuracy_XGB_class = accuracy_score(y_test_2, predictions_XGB_class)
print(accuracy_XGB_class)

precision_XGB_class = precision_score(y_test_2, predictions_XGB_class)
print(precision_XGB_class)

recall_XGB_class = recall_score(y_test_2, predictions_XGB_class)
print(recall_XGB_class)

F1_XGB_class = f1_score(y_test_2, predictions_XGB_class)
print(F1_XGB_class)

roc_auc_XGB_class = roc_auc_score(y_test_2, XGB_class.predict_proba(X_test)[:, 1])
print(roc_auc_XGB_class)


## Visualization of ROC
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt


probs = XGB_class.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = roc_curve(y_test_2, preds)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel

# @title XGB classifier (Confusion matrix)


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


predictions_XGB_class = XGB_class.predict(X_test)

cm_XGB = confusion_matrix(y_test_2, predictions_XGB_class)

cm_XGB_df = pd.DataFrame(cm_XGB, index=[i for i in ["Actual - No", "Actual - Yes"]],
                     columns=[i for i in ["Predicted - No", "Predicted - Yes"]])

plt.figure(figsize=(7,5))

sns.heatmap(cm_XGB_df, annot=True, fmt="d", cmap="YlGnBu")

plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

# @title KNN Classifier (Complete performance metrics)

from sklearn.preprocessing import label_binarize
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix


accuracy_KNN_class = accuracy_score(y_test_2, predictions_KNN_class)
print(accuracy_KNN_class)

precision_KNN_class = precision_score(y_test_2, predictions_KNN_class)
print(precision_KNN_class)

recall_KNN_class = recall_score(y_test_2, predictions_KNN_class)
print(recall_KNN_class)

F1_KNN_class = f1_score(y_test_2, predictions_KNN_class)
print(F1_KNN_class)

roc_auc_KNN_class = roc_auc_score(y_test_2, KNN_class.predict_proba(X_test)[:, 1])
print(roc_auc_KNN_class)


## Visualization of ROC
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt


probs = KNN_class.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = roc_curve(y_test_2, preds)
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel

# @title KNN classifier (Confusion matrix)


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


predictions_KNN_class = KNN_class.predict(X_test)

cm_KNN = confusion_matrix(y_test_2, predictions_KNN_class)

cm_KNN_df = pd.DataFrame(cm_KNN, index=[i for i in ["Actual - No", "Actual - Yes"]],
                     columns=[i for i in ["Predicted - No", "Predicted - Yes"]])

plt.figure(figsize=(7,5))

sns.heatmap(cm_KNN_df, annot=True, fmt="d", cmap="YlGnBu")

plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

# @title Comparative visualization of model performances (Final)


import numpy as np
import matplotlib.pyplot as plt

# Define the metrics and their corresponding scores for each model
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC']
model_names = ['DT classifier', 'RF classifier', 'SVC classifier', 'XGB classifier', 'KNN classifier']

accuracy_scores = [0.670, 0.744, 0.732, 0.739, 0.742]
precision_scores = [0.762, 0.745, 0.788, 0.778, 0.746]
recall_scores = [0.799, 0.989, 0.868, 0.901, 0.983]
f1_scores = [0.780, 0.850, 0.826, 0.835, 0.848]
roc_scores = [0.620, 0.720, 0.698, 0.704, 0.689]

# Combine the scores of all metrics for each model into a single list of lists
all_scores = np.array([accuracy_scores, precision_scores, recall_scores, f1_scores, roc_scores])

# Compute angles for each axis
angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
angles += angles[:1]  # Close the plot

fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))

# Draw one axe per variable and add labels
plt.xticks(angles[:-1], metrics, color='grey', size=10)

# Draw ylabels
ax.set_rlabel_position(0)
plt.yticks([0.25, 0.5, 0.75], ["0.25", "0.50", "0.75"], color="grey", size=7)
plt.ylim(0, 1)

# Plot data
for i in range(len(model_names)):
    values = all_scores[:, i].tolist()
    ax.plot(angles, values + [values[0]], linewidth=1, linestyle='solid', label=model_names[i])  # Connect back to the start point

# Fill area
ax.fill(angles, values + [values[0]], 'b', alpha=0.1)

plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
plt.show()

"""# Feature Importance"""

# @title Feature Selection (Lasso)

# Defining a custom WrapperFeatureSelector class

# from sklearn.base import BaseEstimator, TransformerMixin
# from sklearn.feature_selection import SelectFromModel

# class WrapperFeatureSelection(BaseEstimator, TransformerMixin):
#     def __init__(self, estimator, threshold=0.1):
#         self.estimator = estimator
#         self.threshold = threshold
#         self.feature_selector = None

#     def fit(self, X, y):
#         self.estimator.fit(X, y)
#         self.feature_selector = SelectFromModel(self.estimator, threshold=self.threshold)
#         self.feature_selector.fit(X, y)
#         return self

#     def transform(self, X):
#         if self.feature_selector is None:
#             raise ValueError("The model has not been fitted yet.")
#         return self.feature_selector.transform(X)

#     def get_support(self, indices=False):
#         if self.feature_selector is None:
#             raise ValueError("The model has not been fitted yet.")
#         return self.feature_selector.get_support(indices)

#     def get_params(self, deep=True):
#         return {'estimator': self.estimator, 'threshold': self.threshold}

#     def set_params(self, **params):
#         if 'estimator' in params:
#             self.estimator = params['estimator']
#         if 'threshold' in params:
#             self.threshold = params['threshold']
#         return self


# from sklearn.pipeline import Pipeline
# from sklearn.linear_model import Lasso
# from sklearn.pipeline import make_pipeline

# lasso = Lasso(alpha=0.01)
# feature_selector_lasso = WrapperFeatureSelection(estimator=lasso, threshold=0.1)

# selector_pipeline_lasso = Pipeline([
#     ('preprocessing', preprocessing),
#     ('feature_selector', feature_selector_lasso)
# ])

# selected_features_train_lasso = selector_pipeline_lasso.fit_transform(df_obesity,df_obesity_labels_1)

# selected_feature_indices_lasso = feature_selector_lasso.get_support(indices=True)
# transformed_column_names_lasso = selector_pipeline_lasso.named_steps['preprocessing'].get_feature_names_out()
# selected_column_names_lasso = [transformed_column_names_lasso[idx] for idx in selected_feature_indices_lasso]

# model_coefficients_lasso = feature_selector_lasso.estimator.coef_
# column_importance_map_lasso = dict(zip(selected_column_names_lasso, model_coefficients_lasso))
# sorted_columns_lasso = sorted(column_importance_map_lasso.items(), key=lambda x: abs(x[1]), reverse=True)

# print("Sorted Columns based on Importance:")  # The importances of the features selected by the feature selector (**After** feature selection)
# for column, importance in sorted_columns_lasso:
#     print(f"{column}: {importance}")


# sorted_feature_importance_lasso = sorted(zip(model_coefficients_lasso,
#                                             transformed_column_names_lasso),
#                                         key=lambda x: abs(x[0]), reverse=True)

# print("Sorted Columns based on Importance:")  # The importances of the features **before** fter feature selection
# for importance, column in sorted_feature_importance_lasso:
#     print(f"{column}: {importance}")

# @title Visualizing the Lasso feature selection results

# import matplotlib.pyplot as plt


# top_30_features_lasso = sorted_columns_lasso[:30]


# features, importance = zip(*top_30_features_lasso)

# plt.figure(figsize=(10, 8))
# plt.barh(features, importance, color='skyblue')
# plt.xlabel('Importance')
# plt.title('Top 30 Features')
# plt.gca().invert_yaxis()
# plt.show()

# @title Feature Selection (Wrapper-RF)

# Defining a custom WrapperFeatureSelector class

# from sklearn.base import BaseEstimator, TransformerMixin
# from sklearn.feature_selection import SelectFromModel
# from sklearn.ensemble import RandomForestClassifier

# class WrapperFeatureSelection(BaseEstimator, TransformerMixin):
#     def __init__(self, estimator, threshold=0.1):
#         self.estimator = estimator
#         self.threshold = threshold
#         self.feature_selector = None

#     def fit(self, X, y):
#         self.estimator.fit(X, y)
#         self.feature_selector = SelectFromModel(self.estimator, threshold=self.threshold)
#         self.feature_selector.fit(X, y)
#         return self

#     def transform(self, X):
#         if self.feature_selector is None:
#             raise ValueError("The model has not been fitted yet.")
#         return self.feature_selector.transform(X)

#     def get_support(self, indices=False):
#         if self.feature_selector is None:
#             raise ValueError("The model has not been fitted yet.")
#         return self.feature_selector.get_support(indices)

#     def get_params(self, deep=True):
#         return {'estimator': self.estimator, 'threshold': self.threshold}

#     def set_params(self, **params):
#         if 'estimator' in params:
#             self.estimator = params['estimator']
#         if 'threshold' in params:
#             self.threshold = params['threshold']
#         return self


# from sklearn.pipeline import Pipeline
# from sklearn.linear_model import Lasso
# from sklearn.pipeline import make_pipeline
# # from sklearn.feature_selection import NegativeCorrelationFilter



# # lasso = Lasso(alpha=0.01)
# feature_selector_wrapper_RF = WrapperFeatureSelection(estimator=RandomForestClassifier(random_state=42),threshold=0.01)

# selector_pipeline_wrapper_RF = Pipeline([
#     ('preprocessing', preprocessing),
#     ('feature_selector', feature_selector_wrapper_RF)
# ])


# selected_features_train_wrapper_RF = selector_pipeline_wrapper_RF.fit_transform(df_obesity,df_obesity_labels_2)

# selected_feature_indices_wrapper_RF = feature_selector_wrapper_RF.get_support(indices=True)
# transformed_column_names_wrapper_RF = selector_pipeline_wrapper_RF.named_steps['preprocessing'].get_feature_names_out()
# selected_column_names_wrapper_RF = [transformed_column_names_wrapper_RF[idx] for idx in selected_feature_indices_wrapper_RF]

# if len(selected_feature_indices_wrapper_RF) > 0:
#     # Retrieve feature importances from the RandomForestClassifier
#     model_wrapper_RF = feature_selector_wrapper_RF.estimator
#     importances_wrapper_RF = model_wrapper_RF.feature_importances_

#     # Ensure there are importances available to display
#     if len(importances_wrapper_RF) > 0:
#         # Get selected importances and their corresponding indices
#         selected_importances_wrapper_RF = importances_wrapper_RF[selected_feature_indices_wrapper_RF]

#         # Sort feature importances and select top features
#         num_features_to_display = min(len(selected_importances_wrapper_RF), 30)
#         indices = np.argsort(selected_importances_wrapper_RF)[::-1][:num_features_to_display]
#         sorted_column_names = [selected_column_names_wrapper_RF[idx] for idx in indices]
#         sorted_importances = selected_importances_wrapper_RF[indices]

#         # Plotting feature importances
#         plt.figure(figsize=(10, 8))
#         plt.barh(range(len(sorted_importances)), sorted_importances, align='center')
#         plt.yticks(range(len(sorted_importances)), sorted_column_names)
#         plt.xlabel('Feature Importance')
#         plt.title('Top Selected Features Importance (Random Forest)')
#         plt.gca().invert_yaxis()
#         plt.show()
#     else:
#         print("No importances available to display.")
# else:
#     print("No features were selected.")

# @title Feature Selection (RFE-RF classifier)

# from sklearn.ensemble import RandomForestClassifier
# from sklearn.feature_selection import RFE #the Recursive Feature Elimination (RFE) method from sklearn as a wrapper feature selector
# from sklearn.pipeline import make_pipeline
# from sklearn.pipeline import Pipeline




# estimator_RFE_RF = RandomForestClassifier(random_state=42)

# selector_RFE_RF = RFE(estimator_RFE_RF, n_features_to_select=50, step=1)

# # selector = selector.fit(df_obesity,df_obesity_labels_2)

# RFE_selector_pipeline = Pipeline([
#   ('preprocessing', preprocessing),
#   ('feature_selection', selector_RFE_RF)
# ])

# feature_selector_RFE_RF = RFE_selector_pipeline.fit_transform(df_obesity,df_obesity_labels_2)

# feature_names_RFE_RF = RFE_selector_pipeline.named_steps['preprocessing'].get_feature_names_out()

# ranking_RFE_RF = RFE_selector_pipeline.named_steps['feature_selection'].ranking_

# features_importance_RFE_RF = sorted(list(enumerate(ranking_RFE_RF)), key=lambda x:x[1])

# for feature in features_importance_RFE_RF:
#     print(f"Feature {feature_names_RFE_RF[feature[0]]} importance: {feature[1]}")

# @title Visualizing RFE-RF feaure selector

# import matplotlib.pyplot as plt


# top_30_features_RFE_RF = features_importance_RFE_RF[:30]


# features, importance = zip(*top_30_features_RFE_RF)

# plt.figure(figsize=(10, 8))
# plt.barh(features, importance, color='skyblue')
# plt.xlabel('Importance')
# plt.title('Top 30 Features')
# plt.gca().invert_yaxis()
# plt.show()

"""This code calculates permutation importances for each feature in the dataset based on how much the model performance (measured by accuracy by default) drops when the feature's values are randomly shuffled.

Permutation importances inherently consider both positive and negative associations with the outcome. Features that, when shuffled, result in a considerable drop in model performance are considered more important, regardless of whether they are positively or negatively associated with the outcome.
"""

# @title Permutation importances

# from sklearn.inspection import permutation_importance
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.datasets import make_classification
# from sklearn.pipeline import Pipeline
# import matplotlib.pyplot as plt




# selector_permutation_RF = RandomForestClassifier(random_state=42)

# # Create a pipeline with preprocessing and feature selection using Random Forest
# pipeline_selector_permutation_RF = Pipeline([
#     ('preprocessing', preprocessing),
#     ('feature_selector', selector_permutation_RF)
# ])




# selected_features_permutation_RF = pipeline_selector_permutation_RF.fit(df_obesity,df_obesity_labels_2)

# # Calculate permutation importances
# result = permutation_importance(selected_features_permutation_RF, df_obesity,df_obesity_labels_2, n_repeats=10, random_state=42)

# # Get indices of top 30 features by importance
# top_30_indices = result.importances_mean.argsort()[-30:]

# # Plotting permutation importances for the top 30 features
# plt.figure(figsize=(10, 8))
# plt.barh(range(len(top_30_indices)), result.importances_mean[top_30_indices], align='center')
# plt.yticks(range(len(top_30_indices)), df_obesity.columns[top_30_indices])
# plt.xlabel('Permutation Importance')
# plt.title('Top 30 Feature Importance (Permutation) - Random Forest')
# plt.show()

# @title SHAP (SHapley Additive exPlanations) (Random forest)

!pip install shap
from sklearn.ensemble import RandomForestClassifier

selector_SHAP = RandomForestClassifier(random_state=42, max_depth=61, max_features=24, min_samples_split=81)

from sklearn.ensemble import RandomForestClassifier


pipeline_selector_SHAP = Pipeline([
    ('preprocessing', preprocessing),
    ('feature_selector', selector_SHAP)
])

selected_features_SHAP = pipeline_selector_SHAP.fit(df_obesity,df_obesity_labels_2)

model_for_shap = pipeline_selector_SHAP.named_steps['feature_selector']

import shap

# Calculate SHAP values
# Preprocess the df_obesity data using the same preprocessing steps in the pipeline
preprocessed_df_obesity = pipeline_selector_SHAP.named_steps['preprocessing'].transform(df_obesity)
# Get feature names after preprocessing
transformed_column_names = pipeline_selector_SHAP.named_steps['preprocessing'].get_feature_names_out()



# Calculate SHAP values on the preprocessed data
explainer = shap.Explainer(model_for_shap, preprocessed_df_obesity)
shap_values = explainer.shap_values(preprocessed_df_obesity)



## SHAP values for both negative and positive class

# Calculate mean absolute SHAP values for each feature
mean_abs_shap_values = np.mean([np.abs(sv) for sv in shap_values], axis=0)



## SHAP values only for the positive class

# shap_values_positive_class = shap_values[1]
# mean_abs_shap_values = np.abs(shap_values_positive_class).mean(axis=0)



mean_abs_shap_values_list = mean_abs_shap_values.tolist()


# Combine feature names and their corresponding mean SHAP values
feature_importance = list(zip(transformed_column_names, mean_abs_shap_values_list))

# Sort features based on mean absolute SHAP values (importance)
feature_importance_sorted = sorted(feature_importance, key=lambda x: x[1], reverse=True)

# Display the sorted feature importances
for feature, importance in feature_importance_sorted:
    print(f"{feature}: {importance}")


# Plot the SHAP summary plot with feature names
# import matplotlib.pyplot as plt

feature_importance_sorted = sorted(feature_importance, key=lambda x: x[1], reverse=True)

features_sorted, importances_sorted = zip(*feature_importance_sorted)

# @title Plot the SHAP summary plot with feature names (Random Forest)
import matplotlib.pyplot as plt

# Select the top 30 features
top_features_sorted = features_sorted[:30]
# Flatten importances_sorted
if isinstance(importances_sorted[0], list):
    importances_sorted = [item for sublist in importances_sorted for item in sublist]

# Now select the top 30 features
importances_sorted_top = [importances_sorted[i] for i in range(30)]


print(len(top_features_sorted))
print(len(importances_sorted_top))

# Plot the feature importances
plt.figure(figsize=(10, 8))
plt.title('Top 30 Feature Importances')
plt.barh(range(len(top_features_sorted)), importances_sorted_top, color='b', align='center')
plt.yticks(range(len(top_features_sorted)), top_features_sorted, fontsize=8)
plt.xlabel('Mean Absolute SHAP Value')
plt.gca().invert_yaxis()  # Invert the y-axis to have the feature with the highest importance at the top
plt.show()

# @title SHAP (SHapley Additive exPlanations) (XGBooster)

# !pip install shap
from xgboost import XGBClassifier

selector_SHAP_xgb = XGBClassifier(random_state=42)



pipeline_selector_SHAP_xgb = Pipeline([
    ('preprocessing', preprocessing),
    ('feature_selector_xgb', selector_SHAP_xgb)
])

selected_features_SHAP_xgb = pipeline_selector_SHAP_xgb.fit(df_obesity,df_obesity_labels_2)

model_for_shap_xgb = pipeline_selector_SHAP_xgb.named_steps['feature_selector_xgb']

import shap

# Calculate SHAP values
# Preprocess the df_obesity data using the same preprocessing steps in the pipeline
preprocessed_df_obesity_xgb = pipeline_selector_SHAP_xgb.named_steps['preprocessing'].transform(df_obesity)
# Get feature names after preprocessing
transformed_column_names_xgb = pipeline_selector_SHAP_xgb.named_steps['preprocessing'].get_feature_names_out()

# Calculate SHAP values on the preprocessed data
explainer_xgb = shap.Explainer(model_for_shap_xgb, preprocessed_df_obesity_xgb)
shap_values_xgb = explainer_xgb.shap_values(preprocessed_df_obesity_xgb)

import numpy as np


## SHAP values for both negative and positive class

# Calculate mean absolute SHAP values for each feature
# mean_abs_shap_values = np.mean([np.abs(sv) for sv in shap_values], axis=0)



## SHAP values only for the positive class

shap_values_positive_class_xgb = shap_values_xgb[1]
# Check if shap_values_positive_class_xgb is 1D or 2D
if len(shap_values_positive_class_xgb.shape) == 1:
    # If it's 1D, just take the absolute value
    mean_abs_shap_values_xgb = np.abs(shap_values_positive_class_xgb)
else:
    # If it's 2D, take the mean along axis 0
    mean_abs_shap_values_xgb = np.abs(shap_values_positive_class_xgb).mean(axis=0)



mean_abs_shap_values_list_xgb = mean_abs_shap_values_xgb.tolist()


# Combine feature names and their corresponding mean SHAP values
feature_importance_xgb = list(zip(transformed_column_names_xgb, mean_abs_shap_values_list_xgb))

# Sort features based on mean absolute SHAP values (importance)
feature_importance_sorted_xgb = sorted(feature_importance_xgb, key=lambda x: x[1], reverse=True)

# Display the sorted feature importances
for feature, importance in feature_importance_sorted_xgb:
    print(f"{feature}: {importance}")


# Plot the SHAP summary plot with feature names
# import matplotlib.pyplot as plt

feature_importance_sorted_xgb = sorted(feature_importance_xgb, key=lambda x: x[1], reverse=True)

features_sorted_xgb, importances_sorted_xgb = zip(*feature_importance_sorted_xgb)

# @title Plot the SHAP summary plot with feature names (XGBoost)
import matplotlib.pyplot as plt

# Select the top 30 features
top_features_sorted_xgb = features_sorted_xgb[:30]
# Flatten importances_sorted
if isinstance(importances_sorted_xgb[0], list):
    importances_sorted_xgb = [item for sublist in importances_sorted_xgb for item in sublist]

# Now select the top 30 features
importances_sorted_top_xgb = [importances_sorted_xgb[i] for i in range(30)]


print(len(top_features_sorted_xgb))
print(len(importances_sorted_top_xgb))

# Plot the feature importances
plt.figure(figsize=(10, 8))
plt.title('Top 30 Feature Importances in XGB')
plt.barh(range(len(top_features_sorted_xgb)), importances_sorted_top_xgb, color='b', align='center')
plt.yticks(range(len(top_features_sorted_xgb)), top_features_sorted_xgb, fontsize=8)
plt.xlabel('Mean Absolute SHAP Value in XGB')
plt.gca().invert_yaxis()  # Invert the y-axis to have the feature with the highest importance at the top
plt.show()

# @title Mean importance of the features derived from the two models

# import numpy as np
# import shap
# import matplotlib.pyplot as plt

# # Function to calculate mean SHAP values and sort them
# def calculate_mean_shap_and_sort(explainer_rf, explainer_xgb, preprocessed_data_rf, preprocessed_data_xgb, transformed_column_names_rf, transformed_column_names_xgb):
#     # Calculate SHAP values on the preprocessed data
#     shap_values_rf = explainer_rf.shap_values(preprocessed_data_rf)
#     shap_values_xgb = explainer_xgb.shap_values(preprocessed_data_xgb)

#     # If SHAP values from RF are 3D (multi-class classification), take mean along the first axis
#     if len(shap_values_rf) == 3:
#         shap_values_rf = np.mean(shap_values_rf, axis=0)
#     else:
#         shap_values_rf = shap_values_rf[0]

#     # If SHAP values from XGB are 2D, reshape to match the number of samples
#     if len(shap_values_xgb.shape) == 2:
#         shap_values_xgb = np.expand_dims(shap_values_xgb, axis=0)

#     # Ensure that SHAP values from both models have the same number of features
#     num_features_rf = shap_values_rf.shape[1]
#     num_features_xgb = shap_values_xgb.shape[1]
#     min_num_features = min(num_features_rf, num_features_xgb)
#     shap_values_rf = shap_values_rf[:, :min_num_features]
#     shap_values_xgb = shap_values_xgb[:, :min_num_features]

#     # Combine SHAP values from both models
#     shap_values_combined = np.concatenate((shap_values_rf, shap_values_xgb))

#     # Calculate mean absolute SHAP values for each feature
#     mean_abs_shap_values_combined = np.abs(shap_values_combined).mean(axis=0)

#     # Combine feature names from both models
#     transformed_column_names_combined = transformed_column_names_rf[:min_num_features] + transformed_column_names_xgb[:min_num_features]

#     # Combine feature names and their corresponding mean SHAP values
#     feature_importance_combined = list(zip(transformed_column_names_combined, mean_abs_shap_values_combined))

#     # Sort features based on mean absolute SHAP values (importance)
#     feature_importance_sorted_combined = sorted(feature_importance_combined, key=lambda x: x[1], reverse=True)

#     return feature_importance_sorted_combined

# # Function to plot the top features
# def plot_top_features(feature_importance_sorted, top_n=30):
#     features_sorted, importances_sorted = zip(*feature_importance_sorted[:top_n])
#     y_pos = np.arange(len(features_sorted))
#     plt.figure(figsize=(10, 8))
#     plt.barh(y_pos, importances_sorted, align='center')
#     plt.yticks(y_pos, features_sorted)
#     plt.xlabel('Mean SHAP Values')
#     plt.title('Top 30 Features with Highest Mean SHAP Values')
#     plt.gca().invert_yaxis()
#     plt.show()

# # Calculate SHAP values for RandomForestClassifier
# explainer_rf = shap.Explainer(model_for_shap, preprocessed_df_obesity)
# # Calculate SHAP values for XGBClassifier
# explainer_xgb = shap.Explainer(model_for_shap_xgb, preprocessed_df_obesity_xgb)

# # Calculate mean SHAP values and sort them
# feature_importance_sorted_combined = calculate_mean_shap_and_sort(explainer_rf, explainer_xgb, preprocessed_df_obesity, preprocessed_df_obesity_xgb, transformed_column_names, transformed_column_names_xgb)

# # Print and plot the top features
# print("Top Features:")
# for feature, importance in feature_importance_sorted_combined:
#     print(f"{feature}: {importance}")
# plot_top_features(feature_importance_sorted_combined)

"""# Domain importances"""

# @title Introduction of Domains


feature_to_domain = {
'pipeline-1__RIDAGEYR': 'Sociodemographic',
'pipeline-1__INDFMPIR': 'Socioeconomic',
'pipeline-1__INDFMMPI': 'Socioeconomic',
'pipeline-1__PAD680': 'Physical activity',
'pipeline-1__SLD012': 'Sleep',
'pipeline-1__SLD013': 'Sleep',
'pipeline-1__DR1T_A_DRINKS': 'Dietary' ,
'pipeline-1__Depression_total' : 'Psychologic',
'pipeline-1__Total Fruits': 'Dietary' ,
'pipeline-1__Whole Fruits': 'Dietary' ,
'pipeline-1__Total Vegetables' : 'Dietary' ,
'pipeline-1__Greens and Beans': 'Dietary' ,
'pipeline-1__Whole Grains': 'Dietary' ,
'pipeline-1__Dairy': 'Dietary' ,
'pipeline-1__Total Protein Foods': 'Dietary' ,
'pipeline-1__Seafood and Plant Proteins': 'Dietary' ,
'pipeline-1__Fatty Acids Ratio (PUFAs + MUFAs)/SFAs': 'Dietary' ,
'pipeline-1__Refined Grains': 'Dietary' ,
'pipeline-1__Sodium' :'Dietary' ,
'pipeline-1__Added Sugars': 'Dietary' ,
'pipeline-1__Saturated Fats':'Dietary' ,
'pipeline-1__HEI-2020': 'Dietary' ,
'pipeline-1__Calorie_intake_mean':'Dietary' ,
'pipeline-1__Protein_intake_mean': 'Dietary' ,
'pipeline-1__Carb_intake_mean': 'Dietary' ,
'pipeline-1__Fat_intake_mean': 'Dietary' ,
'pipeline-1__Sugar_intake_mean': 'Dietary' ,
'pipeline-1__Fiber_intake_mean': 'Dietary' ,
'pipeline-1__SAFA_intake_mean': 'Dietary' ,
'pipeline-1__MUFA_intake_mean': 'Dietary' ,
'pipeline-1__PUFA_intake_mean': 'Dietary' ,
'pipeline-1__Cholesterol_intake_mean': 'Dietary' ,
'pipeline-2__RIAGENDR_1.0': 'Sociodemographic',
'pipeline-2__RIAGENDR_2.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_1.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_2.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_3.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_4.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_6.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_7.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_1.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_2.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_77.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_99.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_1.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_2.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_3.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_4.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_5.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_9.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_1.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_2.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_3.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_77.0': 'Sociodemographic',
'pipeline-2__CBQ506_1.0': 'Behavioral',
'pipeline-2__CBQ506_2.0': 'Behavioral',
'pipeline-2__CBQ536_1.0': 'Behavioral',
'pipeline-2__CBQ536_2.0': 'Behavioral',
'pipeline-2__CBQ536_9.0': 'Behavioral',
'pipeline-2__CBQ551_1.0': 'Behavioral',
'pipeline-2__CBQ551_2.0': 'Behavioral',
'pipeline-2__CBQ830_1.0': 'Behavioral',
'pipeline-2__CBQ830_2.0': 'Behavioral',
'pipeline-2__CBQ845_1.0': 'Behavioral',
'pipeline-2__CBQ845_2.0': 'Behavioral',
'pipeline-2__CBQ860_1.0': 'Behavioral',
'pipeline-2__CBQ860_2.0': 'Behavioral',
'pipeline-2__CBQ875_1.0': 'Behavioral',
'pipeline-2__CBQ875_2.0': 'Behavioral',
'pipeline-2__CBQ875_9.0': 'Behavioral',
'pipeline-2__CBQ890_1.0': 'Behavioral',
'pipeline-2__CBQ890_2.0': 'Behavioral',
'pipeline-2__CBQ890_9.0': 'Behavioral',
'pipeline-2__CBQ645_1.0': 'Behavioral',
'pipeline-2__CBQ645_2.0': 'Behavioral',
'pipeline-2__CBQ645_3.0': 'Behavioral',
'pipeline-2__CBQ645_4.0': 'Behavioral',
'pipeline-2__CBQ645_5.0': 'Behavioral',
'pipeline-2__CBQ645_6.0': 'Behavioral',
'pipeline-2__CBQ645_7.0': 'Behavioral',
'pipeline-2__CBQ645_99.0': 'Behavioral',
'pipeline-2__CBQ700_1.0': 'Behavioral',
'pipeline-2__CBQ700_2.0': 'Behavioral',
'pipeline-2__CBQ700_3.0': 'Behavioral',
'pipeline-2__CBQ700_4.0': 'Behavioral',
'pipeline-2__CBQ700_5.0': 'Behavioral',
'pipeline-2__CBQ700_6.0': 'Behavioral',
'pipeline-2__CBQ700_9.0': 'Behavioral',
'pipeline-2__DBQ780_1.0': 'Behavioral',
'pipeline-2__DBQ780_2.0': 'Behavioral',
'pipeline-2__DBQ780_3.0': 'Behavioral',
'pipeline-2__DBQ780_4.0': 'Behavioral',
'pipeline-2__DBQ780_5.0': 'Behavioral',
'pipeline-2__DBQ780_6.0': 'Behavioral',
'pipeline-2__DBQ780_9.0': 'Behavioral',
'pipeline-2__DBQ750_1.0': 'Behavioral',
'pipeline-2__DBQ750_2.0': 'Behavioral',
'pipeline-2__DBQ750_3.0': 'Behavioral',
'pipeline-2__DBQ750_4.0': 'Behavioral',
'pipeline-2__DBQ750_5.0': 'Behavioral',
'pipeline-2__DBQ750_9.0': 'Behavioral',
'pipeline-2__DBQ760_1.0': 'Behavioral',
'pipeline-2__DBQ760_2.0': 'Behavioral',
'pipeline-2__DBQ760_3.0': 'Behavioral',
'pipeline-2__DBQ760_4.0': 'Behavioral',
'pipeline-2__DBQ760_5.0': 'Behavioral',
'pipeline-2__DBQ760_9.0': 'Behavioral',
'pipeline-2__DBQ770_1.0': 'Behavioral',
'pipeline-2__DBQ770_2.0': 'Behavioral',
'pipeline-2__DBQ770_3.0': 'Behavioral',
'pipeline-2__DBQ770_4.0': 'Behavioral',
'pipeline-2__DBQ770_5.0': 'Behavioral',
'pipeline-2__DBQ770_6.0': 'Behavioral',
'pipeline-2__DBQ770_9.0': 'Behavioral',
'pipeline-2__CBQ905_1.0': 'Behavioral',
'pipeline-2__CBQ905_2.0': 'Behavioral',
'pipeline-2__CBQ905_3.0': 'Behavioral',
'pipeline-2__CBQ905_4.0': 'Behavioral',
'pipeline-2__CBQ905_5.0': 'Behavioral',
'pipeline-2__CBQ905_6.0': 'Behavioral',
'pipeline-2__CBQ905_9.0': 'Behavioral',
'pipeline-2__CBQ910_1.0': 'Behavioral',
'pipeline-2__CBQ910_2.0': 'Behavioral',
'pipeline-2__CBQ910_3.0': 'Behavioral',
'pipeline-2__CBQ910_4.0': 'Behavioral',
'pipeline-2__CBQ910_5.0': 'Behavioral',
'pipeline-2__CBQ910_6.0': 'Behavioral',
'pipeline-2__CBQ910_9.0': 'Behavioral',
'pipeline-2__CBQ685_1.0': 'Behavioral',
'pipeline-2__CBQ685_2.0': 'Behavioral',
'pipeline-2__CBQ685_3.0': 'Behavioral',
'pipeline-2__CBQ685_4.0': 'Behavioral',
'pipeline-2__CBQ685_5.0': 'Behavioral',
'pipeline-2__CBQ685_6.0': 'Behavioral',
'pipeline-2__CBQ685_9.0': 'Behavioral',
'pipeline-2__CBQ915_1.0': 'Behavioral',
'pipeline-2__CBQ915_2.0': 'Behavioral',
'pipeline-2__CBQ915_3.0': 'Behavioral',
'pipeline-2__CBQ915_4.0': 'Behavioral',
'pipeline-2__CBQ915_5.0': 'Behavioral',
'pipeline-2__CBQ915_6.0': 'Behavioral',
'pipeline-2__CBQ915_9.0': 'Behavioral',
'pipeline-2__CBD925_1.0': 'Behavioral',
'pipeline-2__CBD925_2.0': 'Behavioral',
'pipeline-2__CBD925_3.0': 'Behavioral',
'pipeline-2__CBD925_7.0': 'Behavioral',
'pipeline-2__CBD925_9.0': 'Behavioral',
'pipeline-2__CBQ930_1.0': 'Behavioral',
'pipeline-2__CBQ930_2.0': 'Behavioral',
'pipeline-2__CBQ930_3.0': 'Behavioral',
'pipeline-2__CBQ930_4.0': 'Behavioral',
'pipeline-2__CBQ930_5.0': 'Behavioral',
'pipeline-2__CBQ930_6.0': 'Behavioral',
'pipeline-2__CBQ930_9.0': 'Behavioral',
'pipeline-2__CBQ935_1.0': 'Behavioral',
'pipeline-2__CBQ935_2.0': 'Behavioral',
'pipeline-2__CBQ935_3.0': 'Behavioral',
'pipeline-2__CBQ935_4.0': 'Behavioral',
'pipeline-2__CBQ935_5.0': 'Behavioral',
'pipeline-2__CBQ935_6.0': 'Behavioral',
'pipeline-2__CBQ935_9.0': 'Behavioral',
'pipeline-2__CBQ945_1.0': 'Behavioral',
'pipeline-2__CBQ945_2.0': 'Behavioral',
'pipeline-2__CBQ945_3.0': 'Behavioral',
'pipeline-2__CBQ945_4.0': 'Behavioral',
'pipeline-2__CBQ945_5.0': 'Behavioral',
'pipeline-2__CBQ945_6.0': 'Behavioral',
'pipeline-2__CBQ945_9.0': 'Behavioral',
'pipeline-2__CBQ950_1.0': 'Behavioral',
'pipeline-2__CBQ950_2.0': 'Behavioral',
'pipeline-2__CBQ950_3.0': 'Behavioral',
'pipeline-2__CBQ950_4.0': 'Behavioral',
'pipeline-2__CBQ950_5.0': 'Behavioral',
'pipeline-2__CBQ950_6.0': 'Behavioral',
'pipeline-2__CBQ950_9.0': 'Behavioral',
'pipeline-2__DBQ700_1.0': 'Behavioral',
'pipeline-2__DBQ700_2.0': 'Behavioral',
'pipeline-2__DBQ700_3.0': 'Behavioral',
'pipeline-2__DBQ700_4.0': 'Behavioral',
'pipeline-2__DBQ700_5.0': 'Behavioral',
'pipeline-2__DBQ700_9.0': 'Behavioral',
'pipeline-2__CBQ596_1.0': 'Behavioral',
'pipeline-2__CBQ596_2.0': 'Behavioral',
'pipeline-2__CBQ596_9.0': 'Behavioral',
'pipeline-2__DRQSDIET_1.0': 'Behavioral',
'pipeline-2__DRQSDIET_2.0': 'Behavioral',
'pipeline-2__DR2STY_1.0': 'Behavioral',
'pipeline-2__DR2STY_2.0': 'Behavioral',
'pipeline-2__FSDHH_1.0': 'Socioeconomic',
'pipeline-2__FSDHH_2.0': 'Socioeconomic',
'pipeline-2__FSDHH_3.0': 'Socioeconomic',
'pipeline-2__FSDHH_4.0': 'Socioeconomic',
'pipeline-2__FSDAD_1.0': 'Socioeconomic',
'pipeline-2__FSDAD_2.0': 'Socioeconomic',
'pipeline-2__FSDAD_3.0': 'Socioeconomic',
'pipeline-2__FSDAD_4.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_1.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_2.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_3.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_7.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_9.0': 'Socioeconomic',
'pipeline-2__MCQ300C_1.0': 'Medical history',
'pipeline-2__MCQ300C_2.0': 'Medical history',
'pipeline-2__MCQ300C_9.0': 'Medical history',
'pipeline-2__MCQ300A_1.0': 'Medical history',
'pipeline-2__MCQ300A_2.0': 'Medical history',
'pipeline-2__MCQ300A_9.0': 'Medical history',
'pipeline-2__PAQ605_1.0': 'Physical activity',
'pipeline-2__PAQ605_2.0': 'Physical activity',
'pipeline-2__PAQ605_9.0': 'Physical activity',
'pipeline-2__PAQ620_1.0': 'Physical activity',
'pipeline-2__PAQ620_2.0': 'Physical activity',
'pipeline-2__PAQ620_9.0': 'Physical activity',
'pipeline-2__PAQ635_1.0': 'Physical activity',
'pipeline-2__PAQ635_2.0': 'Physical activity',
'pipeline-2__PAQ635_9.0': 'Physical activity',
'pipeline-2__PAQ650_1.0': 'Physical activity',
'pipeline-2__PAQ650_2.0': 'Physical activity',
'pipeline-2__PAQ665_1.0': 'Physical activity',
'pipeline-2__PAQ665_2.0': 'Physical activity',
'pipeline-2__PAQ665_9.0': 'Physical activity',
'pipeline-2__SLQ030_0.0': 'Sleep',
'pipeline-2__SLQ030_1.0': 'Sleep',
'pipeline-2__SLQ030_2.0': 'Sleep',
'pipeline-2__SLQ030_3.0': 'Sleep',
'pipeline-2__SLQ030_7.0': 'Sleep',
'pipeline-2__SLQ030_9.0': 'Sleep',
'pipeline-2__SLQ040_0.0': 'Sleep',
'pipeline-2__SLQ040_1.0': 'Sleep',
'pipeline-2__SLQ040_2.0': 'Sleep',
'pipeline-2__SLQ040_3.0': 'Sleep',
'pipeline-2__SLQ040_7.0': 'Sleep',
'pipeline-2__SLQ040_9.0': 'Sleep',
'pipeline-2__SLQ050_1.0': 'Sleep',
'pipeline-2__SLQ050_2.0': 'Sleep',
'pipeline-2__SLQ050_9.0': 'Sleep',
'pipeline-2__SLQ120_0.0': 'Sleep',
'pipeline-2__SLQ120_1.0': 'Sleep',
'pipeline-2__SLQ120_2.0': 'Sleep',
'pipeline-2__SLQ120_3.0': 'Sleep',
'pipeline-2__SLQ120_4.0': 'Sleep',
'pipeline-2__SLQ120_9.0': 'Sleep'
}

# @title Domain importances (With HEI components)

!pip install shap
from sklearn.ensemble import RandomForestClassifier
import shap


# Extract unique domain names
domain_names = set(feature_to_domain.values())

# Create a dictionary to store features within each domain
domain_features = {domain: [] for domain in domain_names}
for feature, domain in feature_to_domain.items():
    domain_features[domain].append(feature)

# Create the pipeline with the preprocessing step
selector_SHAP = RandomForestClassifier(random_state=42, max_depth=61, max_features=24, min_samples_split=81)
pipeline_selector_SHAP = Pipeline([
    ('preprocessing', preprocessing),
    ('feature_selector', selector_SHAP)
])

# Fit the pipeline to the training data
pipeline_selector_SHAP.fit(df_obesity, df_obesity_labels_2)

# Transform the original DataFrame using the preprocessing pipeline
transformed_df = pipeline_selector_SHAP.named_steps['preprocessing'].transform(df_obesity)

# Retrieve the transformed column names
transformed_column_names = pipeline_selector_SHAP.named_steps['preprocessing'].get_feature_names_out()

# Initialize dictionary to store features by domain
X_domain = {}

# Iterate through domain features
for domain, features in domain_features.items():
    # Select columns based on transformed column names
    domain_cols_mask = np.isin(transformed_column_names, features)
    # Retrieve the corresponding columns from the transformed DataFrame
    X_domain[domain] = transformed_df[:, domain_cols_mask]



# Generate synthetic target variable (binary classification)
y = df_obesity_labels_2

# Train a random forest classifier for each domain
# Initialize dictionary to store domain importances
domain_importances = {}

# Iterate through domain features
for domain, X_train_domain in X_domain.items():
    # Fit the classifier
    pipeline_selector_SHAP.named_steps['feature_selector'].fit(X_train_domain, y)

    # Explain the model's predictions using SHAP
    explainer = shap.Explainer(pipeline_selector_SHAP.named_steps['feature_selector'], X_train_domain)
    shap_values = explainer(X_train_domain)

    # Calculate the mean absolute SHAP values
    domain_importances[domain] = np.mean(np.abs(shap_values.values))

sorted_domain_importances= {k: v for k, v in sorted(domain_importances.items(), key=lambda item: item[1], reverse=True)}

print("\nDomain Importances (Training Set):")
for domain, importance in sorted_domain_importances.items():
    print(f"{domain}: {importance:.4f}")

# @title Visualization of domain importances (With HEI components)

# Extract domain names and importances
domain_names = list(sorted_domain_importances.keys())
importances = list(sorted_domain_importances.values())

# Create a horizontal bar plot
plt.figure(figsize=(10, 6))
plt.barh(domain_names, importances, color='skyblue')
plt.xlabel('Importance')
plt.ylabel('Domain')
plt.title('Domain Importances')
plt.gca().invert_yaxis()  # Invert y-axis for readability

# Show the plot
plt.show()

# @title Dataset + Domains without redundant HEI components


df_obesity_comp_rem = df_obesity.drop(columns =['DR1T_A_DRINKS', 'Total Fruits', 'Whole Fruits', 'Total Vegetables', 'Greens and Beans',
                                    'Whole Grains', 'Dairy', 'Total Protein Foods', 'Seafood and Plant Proteins', 'Fatty Acids Ratio (PUFAs + MUFAs)/SFAs',
                                    'Refined Grains', 'Sodium', 'Added Sugars', 'Saturated Fats', 'Sugar_intake_mean',
                                    'Fiber_intake_mean', 'SAFA_intake_mean', 'MUFA_intake_mean', 'PUFA_intake_mean', 'Cholesterol_intake_mean'])

feature_to_domain_comp_rem = {
'pipeline-1__RIDAGEYR': 'Sociodemographic',
'pipeline-1__INDFMPIR': 'Socioeconomic',
'pipeline-1__INDFMMPI': 'Socioeconomic',
'pipeline-1__PAD680': 'Physical activity',
'pipeline-1__SLD012': 'Sleep',
'pipeline-1__SLD013': 'Sleep',
'pipeline-1__Depression_total' : 'Psychologic',
'pipeline-1__HEI-2020': 'Dietary' ,
'pipeline-1__Calorie_intake_mean':'Dietary' ,
'pipeline-1__Protein_intake_mean': 'Dietary' ,
'pipeline-1__Carb_intake_mean': 'Dietary' ,
'pipeline-1__Fat_intake_mean': 'Dietary' ,
'pipeline-2__RIAGENDR_1.0': 'Sociodemographic',
'pipeline-2__RIAGENDR_2.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_1.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_2.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_3.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_4.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_6.0': 'Sociodemographic',
'pipeline-2__RIDRETH3_7.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_1.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_2.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_77.0': 'Sociodemographic',
'pipeline-2__DMDBORN4_99.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_1.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_2.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_3.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_4.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_5.0': 'Sociodemographic',
'pipeline-2__DMDEDUC2_9.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_1.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_2.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_3.0': 'Sociodemographic',
'pipeline-2__DMDMARTZ_77.0': 'Sociodemographic',
'pipeline-2__CBQ506_1.0': 'Behavioral',
'pipeline-2__CBQ506_2.0': 'Behavioral',
'pipeline-2__CBQ536_1.0': 'Behavioral',
'pipeline-2__CBQ536_2.0': 'Behavioral',
'pipeline-2__CBQ536_9.0': 'Behavioral',
'pipeline-2__CBQ551_1.0': 'Behavioral',
'pipeline-2__CBQ551_2.0': 'Behavioral',
'pipeline-2__CBQ830_1.0': 'Behavioral',
'pipeline-2__CBQ830_2.0': 'Behavioral',
'pipeline-2__CBQ845_1.0': 'Behavioral',
'pipeline-2__CBQ845_2.0': 'Behavioral',
'pipeline-2__CBQ860_1.0': 'Behavioral',
'pipeline-2__CBQ860_2.0': 'Behavioral',
'pipeline-2__CBQ875_1.0': 'Behavioral',
'pipeline-2__CBQ875_2.0': 'Behavioral',
'pipeline-2__CBQ875_9.0': 'Behavioral',
'pipeline-2__CBQ890_1.0': 'Behavioral',
'pipeline-2__CBQ890_2.0': 'Behavioral',
'pipeline-2__CBQ890_9.0': 'Behavioral',
'pipeline-2__CBQ645_1.0': 'Behavioral',
'pipeline-2__CBQ645_2.0': 'Behavioral',
'pipeline-2__CBQ645_3.0': 'Behavioral',
'pipeline-2__CBQ645_4.0': 'Behavioral',
'pipeline-2__CBQ645_5.0': 'Behavioral',
'pipeline-2__CBQ645_6.0': 'Behavioral',
'pipeline-2__CBQ645_7.0': 'Behavioral',
'pipeline-2__CBQ645_99.0': 'Behavioral',
'pipeline-2__CBQ700_1.0': 'Behavioral',
'pipeline-2__CBQ700_2.0': 'Behavioral',
'pipeline-2__CBQ700_3.0': 'Behavioral',
'pipeline-2__CBQ700_4.0': 'Behavioral',
'pipeline-2__CBQ700_5.0': 'Behavioral',
'pipeline-2__CBQ700_6.0': 'Behavioral',
'pipeline-2__CBQ700_9.0': 'Behavioral',
'pipeline-2__DBQ780_1.0': 'Behavioral',
'pipeline-2__DBQ780_2.0': 'Behavioral',
'pipeline-2__DBQ780_3.0': 'Behavioral',
'pipeline-2__DBQ780_4.0': 'Behavioral',
'pipeline-2__DBQ780_5.0': 'Behavioral',
'pipeline-2__DBQ780_6.0': 'Behavioral',
'pipeline-2__DBQ780_9.0': 'Behavioral',
'pipeline-2__DBQ750_1.0': 'Behavioral',
'pipeline-2__DBQ750_2.0': 'Behavioral',
'pipeline-2__DBQ750_3.0': 'Behavioral',
'pipeline-2__DBQ750_4.0': 'Behavioral',
'pipeline-2__DBQ750_5.0': 'Behavioral',
'pipeline-2__DBQ750_9.0': 'Behavioral',
'pipeline-2__DBQ760_1.0': 'Behavioral',
'pipeline-2__DBQ760_2.0': 'Behavioral',
'pipeline-2__DBQ760_3.0': 'Behavioral',
'pipeline-2__DBQ760_4.0': 'Behavioral',
'pipeline-2__DBQ760_5.0': 'Behavioral',
'pipeline-2__DBQ760_9.0': 'Behavioral',
'pipeline-2__DBQ770_1.0': 'Behavioral',
'pipeline-2__DBQ770_2.0': 'Behavioral',
'pipeline-2__DBQ770_3.0': 'Behavioral',
'pipeline-2__DBQ770_4.0': 'Behavioral',
'pipeline-2__DBQ770_5.0': 'Behavioral',
'pipeline-2__DBQ770_6.0': 'Behavioral',
'pipeline-2__DBQ770_9.0': 'Behavioral',
'pipeline-2__CBQ905_1.0': 'Behavioral',
'pipeline-2__CBQ905_2.0': 'Behavioral',
'pipeline-2__CBQ905_3.0': 'Behavioral',
'pipeline-2__CBQ905_4.0': 'Behavioral',
'pipeline-2__CBQ905_5.0': 'Behavioral',
'pipeline-2__CBQ905_6.0': 'Behavioral',
'pipeline-2__CBQ905_9.0': 'Behavioral',
'pipeline-2__CBQ910_1.0': 'Behavioral',
'pipeline-2__CBQ910_2.0': 'Behavioral',
'pipeline-2__CBQ910_3.0': 'Behavioral',
'pipeline-2__CBQ910_4.0': 'Behavioral',
'pipeline-2__CBQ910_5.0': 'Behavioral',
'pipeline-2__CBQ910_6.0': 'Behavioral',
'pipeline-2__CBQ910_9.0': 'Behavioral',
'pipeline-2__CBQ685_1.0': 'Behavioral',
'pipeline-2__CBQ685_2.0': 'Behavioral',
'pipeline-2__CBQ685_3.0': 'Behavioral',
'pipeline-2__CBQ685_4.0': 'Behavioral',
'pipeline-2__CBQ685_5.0': 'Behavioral',
'pipeline-2__CBQ685_6.0': 'Behavioral',
'pipeline-2__CBQ685_9.0': 'Behavioral',
'pipeline-2__CBQ915_1.0': 'Behavioral',
'pipeline-2__CBQ915_2.0': 'Behavioral',
'pipeline-2__CBQ915_3.0': 'Behavioral',
'pipeline-2__CBQ915_4.0': 'Behavioral',
'pipeline-2__CBQ915_5.0': 'Behavioral',
'pipeline-2__CBQ915_6.0': 'Behavioral',
'pipeline-2__CBQ915_9.0': 'Behavioral',
'pipeline-2__CBD925_1.0': 'Behavioral',
'pipeline-2__CBD925_2.0': 'Behavioral',
'pipeline-2__CBD925_3.0': 'Behavioral',
'pipeline-2__CBD925_7.0': 'Behavioral',
'pipeline-2__CBD925_9.0': 'Behavioral',
'pipeline-2__CBQ930_1.0': 'Behavioral',
'pipeline-2__CBQ930_2.0': 'Behavioral',
'pipeline-2__CBQ930_3.0': 'Behavioral',
'pipeline-2__CBQ930_4.0': 'Behavioral',
'pipeline-2__CBQ930_5.0': 'Behavioral',
'pipeline-2__CBQ930_6.0': 'Behavioral',
'pipeline-2__CBQ930_9.0': 'Behavioral',
'pipeline-2__CBQ935_1.0': 'Behavioral',
'pipeline-2__CBQ935_2.0': 'Behavioral',
'pipeline-2__CBQ935_3.0': 'Behavioral',
'pipeline-2__CBQ935_4.0': 'Behavioral',
'pipeline-2__CBQ935_5.0': 'Behavioral',
'pipeline-2__CBQ935_6.0': 'Behavioral',
'pipeline-2__CBQ935_9.0': 'Behavioral',
'pipeline-2__CBQ945_1.0': 'Behavioral',
'pipeline-2__CBQ945_2.0': 'Behavioral',
'pipeline-2__CBQ945_3.0': 'Behavioral',
'pipeline-2__CBQ945_4.0': 'Behavioral',
'pipeline-2__CBQ945_5.0': 'Behavioral',
'pipeline-2__CBQ945_6.0': 'Behavioral',
'pipeline-2__CBQ945_9.0': 'Behavioral',
'pipeline-2__CBQ950_1.0': 'Behavioral',
'pipeline-2__CBQ950_2.0': 'Behavioral',
'pipeline-2__CBQ950_3.0': 'Behavioral',
'pipeline-2__CBQ950_4.0': 'Behavioral',
'pipeline-2__CBQ950_5.0': 'Behavioral',
'pipeline-2__CBQ950_6.0': 'Behavioral',
'pipeline-2__CBQ950_9.0': 'Behavioral',
'pipeline-2__DBQ700_1.0': 'Behavioral',
'pipeline-2__DBQ700_2.0': 'Behavioral',
'pipeline-2__DBQ700_3.0': 'Behavioral',
'pipeline-2__DBQ700_4.0': 'Behavioral',
'pipeline-2__DBQ700_5.0': 'Behavioral',
'pipeline-2__DBQ700_9.0': 'Behavioral',
'pipeline-2__CBQ596_1.0': 'Behavioral',
'pipeline-2__CBQ596_2.0': 'Behavioral',
'pipeline-2__CBQ596_9.0': 'Behavioral',
'pipeline-2__DRQSDIET_1.0': 'Behavioral',
'pipeline-2__DRQSDIET_2.0': 'Behavioral',
'pipeline-2__DR2STY_1.0': 'Behavioral',
'pipeline-2__DR2STY_2.0': 'Behavioral',
'pipeline-2__FSDHH_1.0': 'Socioeconomic',
'pipeline-2__FSDHH_2.0': 'Socioeconomic',
'pipeline-2__FSDHH_3.0': 'Socioeconomic',
'pipeline-2__FSDHH_4.0': 'Socioeconomic',
'pipeline-2__FSDAD_1.0': 'Socioeconomic',
'pipeline-2__FSDAD_2.0': 'Socioeconomic',
'pipeline-2__FSDAD_3.0': 'Socioeconomic',
'pipeline-2__FSDAD_4.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_1.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_2.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_3.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_7.0': 'Socioeconomic',
'pipeline-2__INDFMMPC_9.0': 'Socioeconomic',
'pipeline-2__MCQ300C_1.0': 'Medical history',
'pipeline-2__MCQ300C_2.0': 'Medical history',
'pipeline-2__MCQ300C_9.0': 'Medical history',
'pipeline-2__MCQ300A_1.0': 'Medical history',
'pipeline-2__MCQ300A_2.0': 'Medical history',
'pipeline-2__MCQ300A_9.0': 'Medical history',
'pipeline-2__PAQ605_1.0': 'Physical activity',
'pipeline-2__PAQ605_2.0': 'Physical activity',
'pipeline-2__PAQ605_9.0': 'Physical activity',
'pipeline-2__PAQ620_1.0': 'Physical activity',
'pipeline-2__PAQ620_2.0': 'Physical activity',
'pipeline-2__PAQ620_9.0': 'Physical activity',
'pipeline-2__PAQ635_1.0': 'Physical activity',
'pipeline-2__PAQ635_2.0': 'Physical activity',
'pipeline-2__PAQ635_9.0': 'Physical activity',
'pipeline-2__PAQ650_1.0': 'Physical activity',
'pipeline-2__PAQ650_2.0': 'Physical activity',
'pipeline-2__PAQ665_1.0': 'Physical activity',
'pipeline-2__PAQ665_2.0': 'Physical activity',
'pipeline-2__PAQ665_9.0': 'Physical activity',
'pipeline-2__SLQ030_0.0': 'Sleep',
'pipeline-2__SLQ030_1.0': 'Sleep',
'pipeline-2__SLQ030_2.0': 'Sleep',
'pipeline-2__SLQ030_3.0': 'Sleep',
'pipeline-2__SLQ030_7.0': 'Sleep',
'pipeline-2__SLQ030_9.0': 'Sleep',
'pipeline-2__SLQ040_0.0': 'Sleep',
'pipeline-2__SLQ040_1.0': 'Sleep',
'pipeline-2__SLQ040_2.0': 'Sleep',
'pipeline-2__SLQ040_3.0': 'Sleep',
'pipeline-2__SLQ040_7.0': 'Sleep',
'pipeline-2__SLQ040_9.0': 'Sleep',
'pipeline-2__SLQ050_1.0': 'Sleep',
'pipeline-2__SLQ050_2.0': 'Sleep',
'pipeline-2__SLQ050_9.0': 'Sleep',
'pipeline-2__SLQ120_0.0': 'Sleep',
'pipeline-2__SLQ120_1.0': 'Sleep',
'pipeline-2__SLQ120_2.0': 'Sleep',
'pipeline-2__SLQ120_3.0': 'Sleep',
'pipeline-2__SLQ120_4.0': 'Sleep',
'pipeline-2__SLQ120_9.0': 'Sleep'
}

# @title Domain importances (Without HEI components)

!pip install shap
from sklearn.ensemble import RandomForestClassifier
import shap


# Extract unique domain names
domain_names_ed = set(feature_to_domain_comp_rem.values())

# Create a dictionary to store features within each domain
domain_features_ed = {domain_ed: [] for domain_ed in domain_names_ed}
for feature_ed, domain_ed in feature_to_domain_comp_rem.items():
    domain_features_ed[domain_ed].append(feature_ed)

# Create the pipeline with the preprocessing step
selector_SHAP_ed = RandomForestClassifier(random_state=42, max_depth=61, max_features=24, min_samples_split=81)
pipeline_selector_SHAP_ed = Pipeline([
    ('preprocessing', preprocessing),
    ('feature_selector', selector_SHAP_ed)
])

# Fit the pipeline to the training data
pipeline_selector_SHAP_ed.fit(df_obesity_comp_rem, df_obesity_labels_2)

# Transform the original DataFrame using the preprocessing pipeline
transformed_df_ed = pipeline_selector_SHAP_ed.named_steps['preprocessing'].transform(df_obesity_comp_rem)

# Retrieve the transformed column names
transformed_column_names_ed = pipeline_selector_SHAP_ed.named_steps['preprocessing'].get_feature_names_out()

# Initialize dictionary to store features by domain
X_domain_ed = {}

# Iterate through domain features
for domain_ed, features_ed in domain_features_ed.items():
    # Select columns based on transformed column names
    domain_cols_mask_ed = np.isin(transformed_column_names_ed, features_ed)
    # Retrieve the corresponding columns from the transformed DataFrame
    X_domain_ed[domain_ed] = transformed_df_ed[:, domain_cols_mask_ed]



# Generate synthetic target variable (binary classification)
y = df_obesity_labels_2

# Train a random forest classifier for each domain
# Initialize dictionary to store domain importances
domain_importances_ed = {}

# Iterate through domain features
for domain_ed, X_train_domain_ed in X_domain_ed.items():
    X_train_domain_ed_dense = X_train_domain_ed.toarray()
    # Fit the classifier
    pipeline_selector_SHAP_ed.named_steps['feature_selector'].fit(X_train_domain_ed_dense, y)
   # Explain the model's predictions using SHAP
    explainer_ed = shap.Explainer(pipeline_selector_SHAP_ed.named_steps['feature_selector'], X_train_domain_ed_dense)
    shap_values_ed = explainer_ed(X_train_domain_ed_dense, check_additivity=False)
   # Calculate the mean absolute SHAP values
    domain_importances_ed[domain_ed] = np.mean(np.abs(shap_values_ed.values))

sorted_domain_importances_ed = {k: v for k, v in sorted(domain_importances_ed.items(), key=lambda item: item[1], reverse=True)}

print("\nDomain Importances (Training Set):")
for domain_ed, importance_ed in sorted_domain_importances_ed.items():
    print(f"{domain_ed}: {importance_ed:.4f}")

# @title Visualization of domain importances (Without HEI components)


# Extract domain names and importances
domain_names_ed = list(sorted_domain_importances_ed.keys())
importances_ed = list(sorted_domain_importances_ed.values())

# Create a horizontal bar plot
plt.figure(figsize=(10, 6))
plt.barh(domain_names_ed, importances_ed, color='skyblue')
plt.xlabel('Importance')
plt.ylabel('Domain')
plt.title('Domain Importances (Without HEI components)')
plt.gca().invert_yaxis()  # Invert y-axis for readability

# Show the plot
plt.show()

"""# Saving the files"""

# @title Saving the datasets

#%% Saving the files (Separately as for one-day and two-day dietary data)
# save_dataset_excel(df_modified_excl, '/content/drive/MyDrive/2017-prepand NHANES datasets/Modified Dataset(1-day).xlsx')
# save_dataset_excel(df_modified_excl, '/content/drive/MyDrive/2017-prepand NHANES datasets/Modified Dataset(2-days).xlsx')
# save_dataset_excel(modified_df_hei, '/content/drive/MyDrive/2017-prepand NHANES datasets/Modified Dataset (HEI_comp)(2-days).xlsx')
# save_dataset_excel(modified_df_5, '/content/drive/MyDrive/2017-prepand NHANES datasets/Modified Dataset (Final exclusion).xlsx')

# !pip install streamlit

# import streamlit as st